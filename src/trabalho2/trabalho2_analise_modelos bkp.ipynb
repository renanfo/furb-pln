{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Trabalho - Comparação de Modelos de Representação Textual\n",
        "\n",
        "## Embeddings\n",
        "- **BERT**: mBERT\n",
        "- **TF-IDF**\n",
        "- **Word2Vec**\n",
        "\n",
        "Até o momento o projeto faz:\n",
        "1. **Web Scraping** do blog adalbertoday.blogspot.com\n",
        "2. **Processamento de Linguagem Natural** (tokenização, normalização, stemming, lemmatização)\n",
        "3. **Análise Comparativa** entre os três modelos\n",
        "4. **Geração de Relatórios** com estatísticas entre eles\n",
        "\n",
        "## Estrutura do Notebook\n",
        "1. **Configuração Inicial** - Imports e setup, pois em minha máquina preciso fazer import colocando o link do python\n",
        "2. **Processamento PLN** - Classe para limpeza e pré-processamento\n",
        "3. **Web Scraping** - Extração de dados do blog\n",
        "4. **Comparação dos Modelos** - Implementação e análise dos três modelos\n",
        "5. **Execução** - Execução de cada etapa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Configuração Inicial\n",
        "Imports e setup, pois em minha máquina preciso fazer import colocando o link do python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baixando as dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def instalar_dependencias():\n",
        "    dependencias = [\n",
        "        \"pandas\",\n",
        "        \"numpy\", \n",
        "        \"selenium\",\n",
        "        \"nltk\",\n",
        "        \"scikit-learn\",\n",
        "        \"matplotlib\",\n",
        "        \"seaborn\",\n",
        "        \"gensim\",\n",
        "        \"transformers\",\n",
        "        \"torch\"\n",
        "    ]\n",
        "    \n",
        "    print(\"Instalando dependencias com repositorios\")\n",
        "    \n",
        "    for dep in dependencias:\n",
        "        try:\n",
        "            print(f\"Instalando {dep}\")\n",
        "            cmd = [\n",
        "                sys.executable, \"-m\", \"pip\", \"install\", \n",
        "                \"--trusted-host\", \"pypi.org\",\n",
        "                \"--trusted-host\", \"pypi.python.org\", \n",
        "                \"--trusted-host\", \"files.pythonhosted.org\",\n",
        "                \"--index-url\", \"https://pypi.org/simple/\",\n",
        "                \"--upgrade\", dep\n",
        "            ]\n",
        "            \n",
        "            resultado = subprocess.run(cmd, capture_output=True, text=True)\n",
        "            \n",
        "            if resultado.returncode == 0:\n",
        "                print(f\"{dep} instalado\")\n",
        "            else:\n",
        "                print(f\"Erro ao instalar {dep}: {resultado.stderr}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Erro na instalação de {dep}: {e}\")\n",
        "    \n",
        "    print(\"\\nInstalação ok\")\n",
        "\n",
        "instalar_dependencias()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Se der erro acima, tentar esse abaixo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```bash\n",
        "pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org --index-url https://pypi.org/simple/ pandas numpy selenium nltk scikit-learn matplotlib seaborn gensim transformers torch\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Valida se tem todas dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def verificar_dependencias():\n",
        "    dependencias_testar = {\n",
        "        'pandas': 'import pandas as pd',\n",
        "        'numpy': 'import numpy as np', \n",
        "        'selenium': 'from selenium import webdriver',\n",
        "        'nltk': 'import nltk',\n",
        "        'sklearn': 'from sklearn.feature_extraction.text import TfidfVectorizer',\n",
        "        'matplotlib': 'import matplotlib.pyplot as plt',\n",
        "        'seaborn': 'import seaborn as sns',\n",
        "        'gensim': 'from gensim.models import Word2Vec',\n",
        "        'transformers': 'from transformers import AutoTokenizer, AutoModel',\n",
        "        'torch': 'import torch'\n",
        "    }\n",
        "    \n",
        "    print(\"Verificando dependencias instaladas\")\n",
        "    \n",
        "    tudo_ok = True\n",
        "    \n",
        "    for nome, codigo in dependencias_testar.items():\n",
        "        try:\n",
        "            exec(codigo)\n",
        "            print(f\"{nome:<12} - OK\")\n",
        "        except ImportError as e:\n",
        "            print(f\"{nome:<12} - ERRO: {e}\")\n",
        "            tudo_ok = False\n",
        "        except Exception as e:\n",
        "            print(f\"{nome:<12} - AVISO: {e}\")\n",
        "    \n",
        "    if tudo_ok:\n",
        "        print(\"Todas as dependencias estão funcionando\")\n",
        "    else:\n",
        "        print(\"Algumas dependencias faltam\")\n",
        "    \n",
        "    return tudo_ok\n",
        "\n",
        "verificar_dependencias()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports e Dependências\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports basicos\n",
        "import time\n",
        "import hashlib\n",
        "import os\n",
        "from functools import wraps\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# Analise de dados\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Web scraping\n",
        "from selenium import webdriver\n",
        "from selenium.common.exceptions import (\n",
        "    WebDriverException, TimeoutException, StaleElementReferenceException\n",
        ")\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "# Processamento de linguagem natural para o scraper\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer, WordNetLemmatizer\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Machine Learning e modelos\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import PCA\n",
        "from gensim.models import Word2Vec\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Visualização\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualização avançada para clusterização e similaridade\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Classificação com Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Todos os imports realizados\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configurações Globais\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_POSTS = 20  # Número máximo de posts para processar (limitado para notebook)\n",
        "DATABASE_DIR = \"./database/trabalho2\"\n",
        "\n",
        "os.makedirs(DATABASE_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Diretório de dados: {DATABASE_DIR}\")\n",
        "print(f\"Máximo de posts a processar: {MAX_POSTS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup do NLTK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_nltk_resources():\n",
        "    required_resources = [\n",
        "        'punkt', 'stopwords', 'wordnet', 'averaged_perceptron_tagger', 'rslp'\n",
        "    ]\n",
        "    \n",
        "    print(\"Configurando recursos do NLTK\")\n",
        "    for resource in required_resources:\n",
        "        try:\n",
        "            if resource == 'punkt':\n",
        "                nltk.data.find('tokenizers/punkt')\n",
        "            elif resource in ['stopwords', 'wordnet']:\n",
        "                nltk.data.find(f'corpora/{resource}')\n",
        "            elif resource == 'rslp':\n",
        "                nltk.data.find('stemmers/rslp')\n",
        "            else:\n",
        "                nltk.data.find(f'taggers/{resource}')\n",
        "            print(f\"{resource} ja disponivel\")\n",
        "        except LookupError:\n",
        "            print(f\"Baixando recurso NLTK: {resource}\")\n",
        "            nltk.download(resource, quiet=True)\n",
        "            print(f\"{resource} baixado com sucesso\")\n",
        "\n",
        "setup_nltk_resources()\n",
        "print(\"\\nSetup do NLTK concluido\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Funções comuns\n",
        "Coloquei as funções que usarei na integração com as páginas, principalmente para conexão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _hash_text(s: str) -> str:\n",
        "    return hashlib.sha1(s.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n",
        "\n",
        "def _extract_filename_from_url(url: str) -> str:\n",
        "    parsed_url = urlparse(url)\n",
        "    path = parsed_url.path.strip('/')\n",
        "    parts = path.split('/')\n",
        "    \n",
        "    if len(parts) >= 3:\n",
        "        year, month, title = parts[0], parts[1], parts[2]\n",
        "        if title.endswith('.html'):\n",
        "            title = title[:-5]\n",
        "        return f\"{year}-{month}-{title}.txt\"\n",
        "    else:\n",
        "        filename = path.replace('/', '-')\n",
        "        if filename.endswith('.html'):\n",
        "            filename = filename[:-5]\n",
        "        return f\"{filename}.txt\"\n",
        "\n",
        "def build_driver():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--headless=new\")\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    options.add_argument(\"--window-size=1920,1080\")\n",
        "    options.add_argument(\"--log-level=3\")\n",
        "    options.add_argument(\"--remote-allow-origins=*\")\n",
        "    \n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    driver.set_page_load_timeout(60)\n",
        "    return driver\n",
        "\n",
        "RECONECT_EXC = (WebDriverException,)\n",
        "\n",
        "def with_reconnect(method):\n",
        "    @wraps(method)\n",
        "    def wrapper(self, *args, **kwargs):\n",
        "        last_exc = None\n",
        "        for attempt in range(3):\n",
        "            try:\n",
        "                return method(self, *args, **kwargs)\n",
        "            except RECONECT_EXC as e:\n",
        "                last_exc = e\n",
        "                print(f\"Sessão perdida. Reiniciando driver. (tentativa {attempt+1}/3)\")\n",
        "                try: \n",
        "                    self.driver.quit()\n",
        "                except Exception: \n",
        "                    pass\n",
        "                self.driver = build_driver()\n",
        "                self.wait = WebDriverWait(self.driver, 20)\n",
        "                if hasattr(self, 'base_url'):\n",
        "                    try:\n",
        "                        self.driver.get(self.base_url)\n",
        "                        time.sleep(2)\n",
        "                    except Exception as e2:\n",
        "                        print(f\"Falha ao retornar para a URL: {e2}\")\n",
        "                time.sleep(0.5 + attempt * 0.5)\n",
        "            except TimeoutException as e:\n",
        "                last_exc = e\n",
        "                print(f\"Timeout. Tentando novamente. (tentativa {attempt+1}/3)\")\n",
        "                time.sleep(1.2 + attempt * 0.5)\n",
        "        raise last_exc\n",
        "    return wrapper\n",
        "\n",
        "print(\"Funções comuns implementadas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Classe ProcessadorPLN\n",
        "\n",
        "Esta classe implementa:\n",
        "- **Tokenização**: Divisão do texto em sentenças e palavras\n",
        "- **Normalização**: Remoção de pontuação, stopwords e simbolos\n",
        "- **Stemming**: Redução das palavras ao seu radical usando RSLP  \n",
        "- **Lemmatização**: Redução das palavras\n",
        "- **Extração de Metadados**: Identificação de datas, nomes próprios e números"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ProcessadorPLN:\n",
        "    def __init__(self):\n",
        "        self.stemmer = RSLPStemmer()\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stop_words = set(stopwords.words('portuguese'))\n",
        "        print(\"ProcessadorPLN inicializado\")\n",
        "    \n",
        "    def tokenizar(self, texto: str) -> dict:\n",
        "        try:\n",
        "            sentencas = sent_tokenize(texto, language='portuguese')\n",
        "            tokens = word_tokenize(texto.lower(), language='portuguese')\n",
        "            \n",
        "            return {\n",
        "                'sentencas': sentencas,\n",
        "                'tokens': tokens,\n",
        "                'num_sentencas': len(sentencas),\n",
        "                'num_tokens': len(tokens)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Erro na tokenização: {e}\")\n",
        "            return {'sentencas': [], 'tokens': [], 'num_sentencas': 0, 'num_tokens': 0}\n",
        "    \n",
        "    def normalizar_texto(self, tokens: list) -> list:\n",
        "        try:\n",
        "            tokens_limpos = []\n",
        "            for token in tokens:\n",
        "                token_lower = token.lower()\n",
        "                if (token_lower not in string.punctuation and \n",
        "                    not token_lower.isdigit() and \n",
        "                    len(token_lower) > 2):\n",
        "                    tokens_limpos.append(token_lower)\n",
        "            \n",
        "            tokens_sem_stopwords = [\n",
        "                token for token in tokens_limpos \n",
        "                if token not in self.stop_words\n",
        "            ]\n",
        "            \n",
        "            tokens_filtrados = [\n",
        "                token for token in tokens_sem_stopwords \n",
        "                if len(token) >= 3 and any(c.isalpha() for c in token)\n",
        "            ]\n",
        "            \n",
        "            return tokens_filtrados\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Erro na normalização: {e}\")\n",
        "            return []\n",
        "    \n",
        "    def aplicar_stemming(self, tokens: list) -> list:\n",
        "        try:\n",
        "            return [self.stemmer.stem(token) for token in tokens]\n",
        "        except Exception as e:\n",
        "            print(f\"Erro no stemming: {e}\")\n",
        "            return tokens\n",
        "    \n",
        "    def aplicar_lemmatizacao(self, tokens: list) -> list:\n",
        "        try:\n",
        "            lemmas = []\n",
        "            for token in tokens:\n",
        "                lemma = self.lemmatizer.lemmatize(token, pos='n')  # Substantivo\n",
        "                if lemma == token:\n",
        "                    lemma = self.lemmatizer.lemmatize(token, pos='v')  # Verbo\n",
        "                if lemma == token:\n",
        "                    lemma = self.lemmatizer.lemmatize(token, pos='a')  # Adjetivo\n",
        "                lemmas.append(lemma)\n",
        "            return lemmas\n",
        "        except Exception as e:\n",
        "            print(f\"Erro na lemmatização: {e}\")\n",
        "            return tokens\n",
        "    \n",
        "    def extrair_metadados(self, texto: str, url: str) -> dict:\n",
        "        try:\n",
        "            metadados = {\n",
        "                'url': url,\n",
        "                'tamanho_caracteres': len(texto),\n",
        "                'datas_encontradas': [],\n",
        "                'numeros_relevantes': [],\n",
        "                'nomes_proprios': []\n",
        "            }\n",
        "            \n",
        "            # Extração de datas\n",
        "            padrao_data = r'\\b\\d{1,2}[/\\-]\\d{1,2}[/\\-]\\d{2,4}\\b'\n",
        "            datas = re.findall(padrao_data, texto, re.IGNORECASE)\n",
        "            metadados['datas_encontradas'] = list(set(datas))[:5]\n",
        "            \n",
        "            # Extração de números relevantes\n",
        "            numeros = re.findall(r'\\b(?:19|20)\\d{2}\\b|\\b\\d{1,3}(?:[.,]\\d{3})*\\b', texto)\n",
        "            metadados['numeros_relevantes'] = list(set(numeros))[:10]\n",
        "            \n",
        "            # Extração de nomes próprios\n",
        "            entidades = re.findall(r'\\b[A-ZÁÉÍÓÚÂÊÔÀÇ][a-záéíóúâêôàçãõ]{2,}\\b', texto)\n",
        "            palavras_comuns = {'O', 'A', 'Os', 'As', 'E', 'De', 'Da', 'Do', 'Em', 'Na', 'No'}\n",
        "            entidades_filtradas = [e for e in entidades if e not in palavras_comuns]\n",
        "            metadados['nomes_proprios'] = list(set(entidades_filtradas))[:10]\n",
        "            \n",
        "            return metadados\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Erro na extração de metadados: {e}\")\n",
        "            return {'url': url, 'erro': str(e)}\n",
        "    \n",
        "    def processar_texto_completo(self, texto: str, url: str, titulo: str = \"\") -> dict:\n",
        "        try:\n",
        "            # 1. Tokenização\n",
        "            resultado_tokenizacao = self.tokenizar(texto)\n",
        "            tokens_originais = resultado_tokenizacao['tokens']\n",
        "            \n",
        "            # 2. Normalização\n",
        "            tokens_normalizados = self.normalizar_texto(tokens_originais)\n",
        "            \n",
        "            # 3. Stemming\n",
        "            tokens_stemming = self.aplicar_stemming(tokens_normalizados)\n",
        "            \n",
        "            # 4. Lemmatização\n",
        "            tokens_lemmatizacao = self.aplicar_lemmatizacao(tokens_normalizados)\n",
        "            \n",
        "            # 5. Extração de metadados\n",
        "            metadados = self.extrair_metadados(texto, url)\n",
        "            \n",
        "            # 6. Resultado estruturado\n",
        "            resultado = {\n",
        "                'id': url,\n",
        "                'titulo': titulo,\n",
        "                'texto_bruto': texto,\n",
        "                'tokens_originais': tokens_originais,\n",
        "                'tokens_normalizados': tokens_normalizados,\n",
        "                'tokens_stemming': tokens_stemming,\n",
        "                'tokens_lemmatizacao': tokens_lemmatizacao,\n",
        "                'estatisticas': {\n",
        "                    'num_sentencas': resultado_tokenizacao['num_sentencas'],\n",
        "                    'num_tokens_originais': resultado_tokenizacao['num_tokens'],\n",
        "                    'num_tokens_normalizados': len(tokens_normalizados),\n",
        "                    'num_caracteres': len(texto)\n",
        "                },\n",
        "                'metadados': metadados,\n",
        "                'hash_conteudo': _hash_text(texto)\n",
        "            }\n",
        "            \n",
        "            return resultado\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Erro no processamento completo: {e}\")\n",
        "            return {\n",
        "                'id': url,\n",
        "                'titulo': titulo,\n",
        "                'texto_bruto': texto,\n",
        "                'erro_processamento': str(e),\n",
        "                'hash_conteudo': _hash_text(texto)\n",
        "            }\n",
        "\n",
        "print(\"Classe ProcessadorPLN implementada!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AdalbertoScraper:\n",
        "    def __init__(self):\n",
        "        self.driver = build_driver()\n",
        "        self.wait = WebDriverWait(self.driver, 20)\n",
        "        self.base_url = \"https://adalbertoday.blogspot.com/\"\n",
        "        self.processador_pln = ProcessadorPLN()\n",
        "        self.urls_processadas = set()\n",
        "        self.hashes_conteudo = set()\n",
        "        self.resultados = []\n",
        "        \n",
        "        print(f\"AdalbertoScraper inicializado - máximo {MAX_POSTS} posts\")\n",
        "    \n",
        "    def _get(self, url):\n",
        "        self.driver.get(url)\n",
        "    \n",
        "    def _extrair_texto_limpo(self, elemento) -> str:\n",
        "        try:\n",
        "            texto = elemento.text\n",
        "            if not texto:\n",
        "                texto = self.driver.execute_script(\"return arguments[0].textContent;\", elemento)\n",
        "            \n",
        "            texto = re.sub(r'\\s+', ' ', texto)\n",
        "            texto = re.sub(r'\\n\\s*\\n', '\\n\\n', texto)\n",
        "            \n",
        "            return texto.strip()\n",
        "        except Exception as e:\n",
        "            print(f\"Erro na extração de texto: {e}\")\n",
        "            return \"\"\n",
        "    \n",
        "    @with_reconnect\n",
        "    def abrir_blog(self):\n",
        "        print(f\"Abrindo blog: {self.base_url}\")\n",
        "        self._get(self.base_url)\n",
        "        self.wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
        "        print(\"Blog acessado com sucesso\")\n",
        "    \n",
        "    @with_reconnect\n",
        "    def encontrar_links_posts(self) -> list:\n",
        "        print(\"Procurando links dos posts\")\n",
        "        \n",
        "        try:\n",
        "            self.wait.until(EC.presence_of_element_located((By.TAG_NAME, \"a\")))\n",
        "            elementos_link = self.driver.find_elements(By.TAG_NAME, \"a\")\n",
        "            \n",
        "            links_encontrados = []\n",
        "            for elemento in elementos_link:\n",
        "                try:\n",
        "                    href = elemento.get_attribute(\"href\")\n",
        "                    if href and 'adalbertoday.blogspot.com' in href:\n",
        "                        if re.search(r'/\\d{4}/\\d{2}/', href):\n",
        "                            if href not in links_encontrados:\n",
        "                                links_encontrados.append(href)\n",
        "                except Exception:\n",
        "                    continue\n",
        "            \n",
        "            print(f\"{len(links_encontrados)} posts encontrados\")\n",
        "            return links_encontrados\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao buscar links: {e}\")\n",
        "            return []\n",
        "    \n",
        "    @with_reconnect\n",
        "    def processar_post(self, url: str) -> dict:\n",
        "        print(f\"Processando post: {url}\")\n",
        "        \n",
        "        try:\n",
        "            if url in self.urls_processadas:\n",
        "                return None\n",
        "            \n",
        "            self._get(url)\n",
        "            self.wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
        "            \n",
        "            # Extrair título\n",
        "            try:\n",
        "                titulo_elem = self.wait.until(\n",
        "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"h3.post-title, .entry-title, .post-title\"))\n",
        "                )\n",
        "                titulo = titulo_elem.text.strip() if titulo_elem else \"Sem título\"\n",
        "            except:\n",
        "                titulo = \"Sem título\"\n",
        "            \n",
        "            # Extrair conteúdo\n",
        "            try:\n",
        "                conteudo_elem = self.wait.until(\n",
        "                    EC.presence_of_element_located((By.CSS_SELECTOR, \".post-body, .entry-content, .post-content\"))\n",
        "                )\n",
        "                texto_limpo = self._extrair_texto_limpo(conteudo_elem)\n",
        "            except:\n",
        "                print(\"Texto do post não encontrado\")\n",
        "                return None\n",
        "            \n",
        "            # Verificar duplicação\n",
        "            hash_conteudo = _hash_text(texto_limpo)\n",
        "            if hash_conteudo in self.hashes_conteudo:\n",
        "                return None\n",
        "\n",
        "            # Processar com PLN\n",
        "            resultado = self.processador_pln.processar_texto_completo(\n",
        "                texto_limpo, url, titulo\n",
        "            )\n",
        "            \n",
        "            self.urls_processadas.add(url)\n",
        "            self.hashes_conteudo.add(hash_conteudo)\n",
        "            \n",
        "            print(f\"Post processado: {titulo[:50]}...\")\n",
        "            print(f\"   Caracteres: {len(texto_limpo)}\")\n",
        "            print(f\"   Tokens normalizados: {len(resultado.get('tokens_normalizados', []))}\")\n",
        "            \n",
        "            return resultado\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar post {url}: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def _salvar_arquivo_individual(self, resultado: dict, url: str):\n",
        "        try:\n",
        "            nome_arquivo = _extract_filename_from_url(url)\n",
        "            caminho = os.path.join(DATABASE_DIR, nome_arquivo)\n",
        "            \n",
        "            with open(caminho, 'w', encoding='utf-8') as f:\n",
        "                f.write(resultado.get('texto_bruto', ''))\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao salvar arquivo: {e}\")\n",
        "    \n",
        "    def processar_lista_posts(self):\n",
        "        try:\n",
        "            self.abrir_blog()\n",
        "            links_posts = self.encontrar_links_posts()\n",
        "            \n",
        "            if not links_posts:\n",
        "                print(\"Nenhum post encontrado\")\n",
        "                return\n",
        "            \n",
        "            if len(links_posts) > MAX_POSTS:\n",
        "                print(f\"Limitando processamento a {MAX_POSTS} posts\")\n",
        "                links_posts = links_posts[:MAX_POSTS]\n",
        "            \n",
        "            print(f\"\\nProcessando {len(links_posts)} posts\")\n",
        "            \n",
        "            for i, url in enumerate(links_posts, 1):\n",
        "                print(f\"\\n[{i}/{len(links_posts)}] Processando post {i}\")\n",
        "                \n",
        "                resultado = self.processar_post(url)\n",
        "                if resultado:\n",
        "                    self.resultados.append(resultado)\n",
        "                    self._salvar_arquivo_individual(resultado, url)\n",
        "                \n",
        "                if i < len(links_posts):\n",
        "                    time.sleep(2)  # Pausa entre requisições\n",
        "            \n",
        "            print(f\"\\nProcessamento concluído: {len(self.resultados)} posts processados\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Erro no scraping: {e}\")\n",
        "    \n",
        "    def close(self):\n",
        "        try:\n",
        "            self.driver.quit()\n",
        "            print(\"Navegador fechado\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "print(\"Classe AdalbertoScraper implementada\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Classe ComparadorModelos\n",
        "\n",
        "Esta classe implementa e compara os três modelos de representação textual:\n",
        "- **BERT**\n",
        "- **TF-IDF**\n",
        "- **Word2Vec**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ComparadorModelos:\n",
        "    def __init__(self):\n",
        "        print(\"Inicializando ComparadorModelos...\")\n",
        "        \n",
        "        self.bert_model_name = \"neuralmind/bert-base-portuguese-cased\"\n",
        "        self.bert_tokenizer = None\n",
        "        self.bert_model = None\n",
        "        \n",
        "        self.tfidf_vectorizer = TfidfVectorizer(\n",
        "            max_features=1000,\n",
        "            ngram_range=(1, 2),\n",
        "            min_df=2,\n",
        "            max_df=0.95\n",
        "        )\n",
        "        \n",
        "        self.word2vec_model = None\n",
        "        self.resultados_comparacao = {}\n",
        "        \n",
        "        print(\"ComparadorModelos inicializado\")\n",
        "    \n",
        "    def _carregar_bert(self):\n",
        "        if self.bert_tokenizer is None or self.bert_model is None:\n",
        "            print(\"Carregando modelo BERT\")\n",
        "            try:\n",
        "                # Inicio do encode_sentences da Aula 7\n",
        "                # como meu texto é portugues do adalbertoday, tento usar em português\n",
        "                self.bert_tokenizer = AutoTokenizer.from_pretrained(self.bert_model_name)\n",
        "                self.bert_model = AutoModel.from_pretrained(self.bert_model_name)\n",
        "                self.bert_model.eval()\n",
        "                print(\"BERT carregado com sucesso\")\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao carregar BERT: {e}\")\n",
        "                print(\"Tentando modelo multilingual\")\n",
        "                self.bert_model_name = \"bert-base-multilingual-cased\"\n",
        "                self.bert_tokenizer = AutoTokenizer.from_pretrained(self.bert_model_name)\n",
        "                self.bert_model = AutoModel.from_pretrained(self.bert_model_name)\n",
        "                self.bert_model.eval()\n",
        "                print(\"BERT multilingual carregado\")\n",
        "    \n",
        "    def processar_textos_bert(self, textos: list) -> np.ndarray:\n",
        "        self._carregar_bert()\n",
        "        \n",
        "        print(f\"Processando {len(textos)} textos com BERT\")\n",
        "        embeddings = []\n",
        "        inicio = time.time() # usado pra comparar os outros modelos para saber qual mais rápido\n",
        "        \n",
        "        for i, texto in enumerate(textos):\n",
        "            try:\n",
        "                inputs = self.bert_tokenizer(\n",
        "                    texto, \n",
        "                    return_tensors=\"pt\", \n",
        "                    truncation=True, \n",
        "                    padding=True, \n",
        "                    max_length=512 # coloquei 512 pois vi que o BERT não suporta tanto, estava dando erro quando não coloquei\n",
        "                )\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    outputs = self.bert_model(**inputs)\n",
        "                    embedding = outputs.last_hidden_state[:, 0, :].numpy()\n",
        "                    embeddings.append(embedding.flatten())\n",
        "                \n",
        "                if (i + 1) % 5 == 0:\n",
        "                    print(f\"- BERT: {i + 1}/{len(textos)} processados\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"Erro no texto {i}: {e}\")\n",
        "                embeddings.append(np.zeros(768))\n",
        "        \n",
        "        tempo_total = time.time() - inicio\n",
        "        print(f\"BERT concluído em {tempo_total:.2f}s\")\n",
        "        return np.array(embeddings)\n",
        "    \n",
        "    def processar_textos_tfidf(self, textos: list) -> np.ndarray:\n",
        "        print(f\"Processando {len(textos)} textos com TF-IDF\")\n",
        "        \n",
        "        inicio = time.time()\n",
        "        try:\n",
        "            matriz_tfidf = self.tfidf_vectorizer.fit_transform(textos)\n",
        "            embeddings = matriz_tfidf.toarray()\n",
        "            \n",
        "            tempo_total = time.time() - inicio\n",
        "            print(f\"TF-IDF concluído em {tempo_total:.2f}s\")\n",
        "            print(f\"- Dimensões: {embeddings.shape}\")\n",
        "            \n",
        "            return embeddings\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Erro no TF-IDF: {e}\")\n",
        "            return np.zeros((len(textos), 1000))\n",
        "    \n",
        "    def processar_textos_word2vec(self, tokens_normalizados: list) -> np.ndarray:\n",
        "        print(f\"Treinando Word2Vec com {len(tokens_normalizados)} documentos\")\n",
        "        \n",
        "        inicio = time.time()\n",
        "        try:\n",
        "            # Vi essa configuração na internet, não sei se é a melhor\n",
        "            # mas vi em dois tutoriais diferentes que usavam algumas dessas configurações\n",
        "            self.word2vec_model = Word2Vec(\n",
        "                sentences=tokens_normalizados,\n",
        "                vector_size=300,\n",
        "                window=5,\n",
        "                min_count=2,\n",
        "                workers=4,\n",
        "                epochs=10\n",
        "            )\n",
        "            \n",
        "            print(f\"Vocabulário Word2Vec: {len(self.word2vec_model.wv.key_to_index)} palavras\")\n",
        "            \n",
        "            embeddings = []\n",
        "            for tokens in tokens_normalizados:\n",
        "                if not tokens:\n",
        "                    embeddings.append(np.zeros(300))\n",
        "                    continue\n",
        "                \n",
        "                vetores_palavras = []\n",
        "                for token in tokens:\n",
        "                    if token in self.word2vec_model.wv:\n",
        "                        vetores_palavras.append(self.word2vec_model.wv[token])\n",
        "                \n",
        "                if vetores_palavras:\n",
        "                    embedding_medio = np.mean(vetores_palavras, axis=0)\n",
        "                    embeddings.append(embedding_medio)\n",
        "                else:\n",
        "                    embeddings.append(np.zeros(300))\n",
        "            \n",
        "            tempo_total = time.time() - inicio\n",
        "            print(f\"Word2Vec concluído em {tempo_total:.2f}s\")\n",
        "            return np.array(embeddings)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Erro no Word2Vec: {e}\")\n",
        "            return np.zeros((len(tokens_normalizados), 300))\n",
        "    \n",
        "    def calcular_similaridades(self, embeddings: np.ndarray, nome_modelo: str) -> dict:\n",
        "        print(f\"Calculando similaridades para {nome_modelo}\")\n",
        "        \n",
        "        try:\n",
        "            matriz_sim = cosine_similarity(embeddings)\n",
        "            \n",
        "            mask = ~np.eye(matriz_sim.shape[0], dtype=bool)\n",
        "            similaridades = matriz_sim[mask]\n",
        "            \n",
        "            stats = {\n",
        "                'modelo': nome_modelo,\n",
        "                'dimensoes': embeddings.shape[1],\n",
        "                'num_documentos': embeddings.shape[0],\n",
        "                'similaridade_media': np.mean(similaridades),\n",
        "                'similaridade_std': np.std(similaridades),\n",
        "                'similaridade_min': np.min(similaridades),\n",
        "                'similaridade_max': np.max(similaridades),\n",
        "                'matriz_similaridade': matriz_sim\n",
        "            }\n",
        "            \n",
        "            return stats\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Erro no cálculo de similaridades: {e}\")\n",
        "            return {'modelo': nome_modelo, 'erro': str(e)}\n",
        "    \n",
        "    def comparar_modelos(self, dados_processados: list) -> dict:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"INICIANDO COMPARAÇÃO DE MODELOS\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        if not dados_processados:\n",
        "            print(\"Nenhum dado para processar, validar se o blog foi processado corretamente\")\n",
        "            return {}\n",
        "        \n",
        "        textos_brutos = [item.get('texto_bruto', '') for item in dados_processados]\n",
        "        tokens_normalizados = [item.get('tokens_normalizados', []) for item in dados_processados]\n",
        "        \n",
        "        print(f\"Processando {len(textos_brutos)} documentos\")\n",
        "        \n",
        "        indices_validos = [i for i, texto in enumerate(textos_brutos) if texto.strip()]\n",
        "        textos_validos = [textos_brutos[i] for i in indices_validos]\n",
        "        tokens_validos = [tokens_normalizados[i] for i in indices_validos]\n",
        "        \n",
        "        print(f\"Documentos válidos: {len(textos_validos)}\")\n",
        "        \n",
        "        resultados = {}\n",
        "        \n",
        "        # TF-IDF\n",
        "        try:\n",
        "            print(\"\\nTF-IDF\")\n",
        "            print(\"-\" * 30)\n",
        "            embeddings_tfidf = self.processar_textos_tfidf(textos_validos)\n",
        "            resultados['tfidf'] = self.calcular_similaridades(embeddings_tfidf, \"TF-IDF\")\n",
        "        except Exception as e:\n",
        "            print(f\"Erro no TF-IDF: {e}\")\n",
        "            resultados['tfidf'] = {'modelo': 'TF-IDF', 'erro': str(e)}\n",
        "        \n",
        "        # Word2Vec\n",
        "        try:\n",
        "            print(\"\\nWord2Vec\")\n",
        "            print(\"-\" * 30)\n",
        "            embeddings_w2v = self.processar_textos_word2vec(tokens_validos)\n",
        "            resultados['word2vec'] = self.calcular_similaridades(embeddings_w2v, \"Word2Vec\")\n",
        "        except Exception as e:\n",
        "            print(f\"Erro no Word2Vec: {e}\")\n",
        "            resultados['word2vec'] = {'modelo': 'Word2Vec', 'erro': str(e)}\n",
        "        \n",
        "        # BERT\n",
        "        try:\n",
        "            print(\"\\nBERT\")\n",
        "            print(\"-\" * 30)\n",
        "            embeddings_bert = self.processar_textos_bert(textos_validos)\n",
        "            resultados['bert'] = self.calcular_similaridades(embeddings_bert, \"BERT\")\n",
        "        except Exception as e:\n",
        "            print(f\"Erro no BERT: {e}\")\n",
        "            resultados['bert'] = {'modelo': 'BERT', 'erro': str(e)}\n",
        "        \n",
        "        self.resultados_comparacao = resultados\n",
        "        return resultados\n",
        "\n",
        "print(\"Classe ComparadorModelos implementada\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Análise Avançada: Clusterização e Similaridade\n",
        "\n",
        "Esta seção implementa análises avançadas inspiradas no exemplo do professor:\n",
        "- **Tabelas de Similaridade**: Heatmaps interativos para visualizar proximidade entre documentos\n",
        "- **Clusterização K-Means**: Agrupamento automático de documentos por similaridade\n",
        "- **Visualização 2D**: Projeção com PCA para scatter plots comparativos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_similarity_heatmap_px(\n",
        "    X,\n",
        "    titulos=None,           # lista de títulos dos documentos para o hover\n",
        "    title=\"Similaridade (cosseno)\",\n",
        "    cmap=\"Blues\",\n",
        "    mask_upper=False,       # True: mostra só triângulo inferior\n",
        "    vmin=0.0, vmax=1.0,\n",
        "    cbar_label=\"Similaridade\",\n",
        "    width=800, height=700,\n",
        "    fmt=\".3f\",              # formatação do label interno\n",
        "    text_font_size=10,\n",
        "    text_font_color=\"black\",\n",
        "    xgap=1, ygap=1,         # \"espessura\" das linhas entre células\n",
        "    use_plotly=True         # Usa plotly ou matplotlib, eu estava com problema para usar o plotly, mas vi que é problema é no repository do mercado livre, que não tem suporte para plotly\n",
        "):\n",
        "    # 1) Similaridade cosseno\n",
        "    S = cosine_similarity(X)\n",
        "    n = S.shape[0]\n",
        "    labels = [f\"Post {i+1}\" for i in range(n)]\n",
        "\n",
        "    # 2) Máscara (triângulo superior) se solicitada\n",
        "    Z = S.astype(float).copy()\n",
        "    if mask_upper:\n",
        "        iu = np.triu_indices(n, k=1)\n",
        "        Z[iu] = np.nan\n",
        "\n",
        "    fig = None\n",
        "    \n",
        "    # Verifica qual biblioteca usar\n",
        "    if use_plotly:\n",
        "        try:\n",
        "            # 3) Labels numéricos dentro das células\n",
        "            text_matrix = np.empty((n, n), dtype=object)\n",
        "            text_matrix[:] = \"\"\n",
        "            for i in range(n):\n",
        "                for j in range(n):\n",
        "                    if not np.isnan(Z[i, j]):\n",
        "                        text_matrix[i, j] = f\"{Z[i, j]:{fmt}}\"\n",
        "\n",
        "            # 4) Hover com títulos dos posts\n",
        "            customdata = np.empty((n, n), dtype=object)\n",
        "            customdata[:] = \"\"\n",
        "            for i in range(n):\n",
        "                for j in range(n):\n",
        "                    if not np.isnan(Z[i, j]):\n",
        "                        titulo1 = titulos[i][:50] + \"...\" if titulos and len(titulos[i]) > 50 else (titulos[i] if titulos else labels[i])\n",
        "                        titulo2 = titulos[j][:50] + \"...\" if titulos and len(titulos[j]) > 50 else (titulos[j] if titulos else labels[j])\n",
        "                        customdata[i, j] = f\"<b>{labels[i]}</b>: {titulo1}<br><b>{labels[j]}</b>: {titulo2}<br><b>Similaridade:</b> {Z[i, j]:.3f}\"\n",
        "\n",
        "            # 5) Construir heatmap\n",
        "            fig = go.Figure(\n",
        "                data=go.Heatmap(\n",
        "                    z=Z,\n",
        "                    x=labels,\n",
        "                    y=labels,\n",
        "                    zmin=vmin, zmax=vmax,\n",
        "                    colorscale=cmap,\n",
        "                    colorbar=dict(title=cbar_label),\n",
        "                    # labels internos\n",
        "                    text=text_matrix,\n",
        "                    texttemplate=\"%{text}\",\n",
        "                    textfont=dict(color=text_font_color, size=text_font_size),\n",
        "                    # hover personalizado\n",
        "                    customdata=customdata,\n",
        "                    hovertemplate=\"%{customdata}<extra></extra>\",\n",
        "                    # grades entre células\n",
        "                    xgap=xgap, ygap=ygap\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # Layout\n",
        "            fig.update_layout(\n",
        "                title=title,\n",
        "                width=width, height=height,\n",
        "                template=\"plotly_white\",\n",
        "                margin=dict(l=80, r=30, t=80, b=60),\n",
        "            )\n",
        "            # Células quadradas e origem no topo\n",
        "            fig.update_yaxes(autorange=\"reversed\", scaleanchor=\"x\", scaleratio=1)\n",
        "\n",
        "            fig.show()\n",
        "            print(f\"Heatmap interativo gerado: {title}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Erro no plotly: {e}\")\n",
        "            print(\"Gerando versão matplotlib como alternativa\")\n",
        "            use_plotly = False\n",
        "    \n",
        "    if not use_plotly:\n",
        "        try:\n",
        "            # Versão Matplotlib (fallback)\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            \n",
        "            # Criar heatmap com seaborn/matplotlib\n",
        "            mask = np.triu(np.ones_like(Z, dtype=bool)) if mask_upper else None\n",
        "            \n",
        "            ax = sns.heatmap(\n",
        "                Z, \n",
        "                annot=True, \n",
        "                fmt=fmt, \n",
        "                cmap=cmap,\n",
        "                vmin=vmin, \n",
        "                vmax=vmax,\n",
        "                xticklabels=labels,\n",
        "                yticklabels=labels,\n",
        "                mask=mask,\n",
        "                square=True,\n",
        "                cbar_kws={'label': cbar_label}\n",
        "            )\n",
        "            \n",
        "            plt.title(title, fontsize=14, fontweight='bold')\n",
        "            plt.xlabel('Posts', fontsize=12)\n",
        "            plt.ylabel('Posts', fontsize=12)\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.yticks(rotation=0)\n",
        "            plt.tight_layout()\n",
        "            \n",
        "            if titulos:\n",
        "                plt.figtext(0.02, 0.02, f\"Títulos: {', '.join([f'P{i+1}: {t[:20]}...' for i, t in enumerate(titulos[:5])])}\", \n",
        "                           fontsize=8, style='italic')\n",
        "            \n",
        "            plt.show()\n",
        "            fig = plt.gcf()\n",
        "            print(f\"Heatmap matplotlib gerado: {title}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Erro também no matplotlib: {e}\")\n",
        "            print(\"Mostrando estatísticas\")\n",
        "            \n",
        "            # Fallback final: só estatísticas\n",
        "            print(f\"\\n{title}\")\n",
        "            print(\"-\" * 50)\n",
        "            print(f\"Dimensões da matriz: {Z.shape}\")\n",
        "            print(f\"Similaridade média: {np.nanmean(Z[~np.eye(Z.shape[0], dtype=bool)]):.4f}\")\n",
        "            print(f\"Similaridade mín: {np.nanmin(Z[~np.eye(Z.shape[0], dtype=bool)]):.4f}\")\n",
        "            print(f\"Similaridade máx: {np.nanmax(Z[~np.eye(Z.shape[0], dtype=bool)]):.4f}\")\n",
        "            \n",
        "            # Mostrar matriz resumida\n",
        "            print(\"\\nMatriz de Similaridade resumida para ver melhor:\")\n",
        "            print(f\"{'':>8}\", end=\"\")\n",
        "            for j in range(min(5, Z.shape[1])):\n",
        "                print(f\"{labels[j]:>8}\", end=\"\")\n",
        "            print()\n",
        "            \n",
        "            for i in range(min(5, Z.shape[0])):\n",
        "                print(f\"{labels[i]:>8}\", end=\"\")\n",
        "                for j in range(min(5, Z.shape[1])):\n",
        "                    print(f\"{Z[i,j]:>8.3f}\", end=\"\")\n",
        "                print()\n",
        "\n",
        "    return S, fig\n",
        "\n",
        "print(\"Função de heatmap de similaridade implementada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_kmeans_clustering(X, n_clusters=3, random_state=42):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init='auto')\n",
        "    labels = kmeans.fit_predict(X)\n",
        "    \n",
        "    return {\n",
        "        'labels': labels,\n",
        "        'centers': kmeans.cluster_centers_,\n",
        "        'inertia': kmeans.inertia_,\n",
        "        'n_clusters': n_clusters\n",
        "    }\n",
        "\n",
        "def reduce_to_2d(X, method=\"pca\", random_state=42):\n",
        "    if method.lower() == \"pca\":\n",
        "        reducer = PCA(n_components=2, random_state=random_state)\n",
        "        Z = reducer.fit_transform(X)\n",
        "        explained_variance = reducer.explained_variance_ratio_\n",
        "        return Z, explained_variance\n",
        "    else:\n",
        "        raise ValueError(\"Atualmente apenas 'pca' é suportado\") # mudei a mensagem que o professor usou na aula 7\n",
        "\n",
        "print(\"Funções de clusterização implementada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_scatter_comparison_2d(embeddings_dict, dados_processados, n_clusters=3, random_state=42):\n",
        "    # extrai títulos dos posts\n",
        "    titulos = [item.get('titulo', f\"Post {i+1}\") for i, item in enumerate(dados_processados)]\n",
        "    \n",
        "    rows = []\n",
        "    \n",
        "    for modelo_nome, X in embeddings_dict.items():\n",
        "        if X is None or len(X) == 0:\n",
        "            continue\n",
        "            \n",
        "        # clusterização\n",
        "        cluster_result = run_kmeans_clustering(X, n_clusters=n_clusters, random_state=random_state)\n",
        "        labels = cluster_result['labels']\n",
        "        \n",
        "        # redução\n",
        "        Z, explained_var = reduce_to_2d(X, method=\"pca\", random_state=random_state)\n",
        "        \n",
        "        for i, (titulo, label) in enumerate(zip(titulos, labels)):\n",
        "            rows.append({\n",
        "                'modelo': modelo_nome.upper(),\n",
        "                'titulo': titulo,\n",
        "                'titulo_curto': titulo[:30] + \"...\" if len(titulo) > 30 else titulo,\n",
        "                'post_id': f\"Post {i+1}\",\n",
        "                'x': Z[i, 0],\n",
        "                'y': Z[i, 1],\n",
        "                'cluster': f\"Cluster {label}\",\n",
        "                'explained_var_x': explained_var[0],\n",
        "                'explained_var_y': explained_var[1],\n",
        "                'inertia': cluster_result['inertia']\n",
        "            })\n",
        "    \n",
        "    df_results = pd.DataFrame(rows)\n",
        "    \n",
        "    if len(df_results) == 0:\n",
        "        print(\"Nenhum dado válido\")\n",
        "        return None, None\n",
        "    \n",
        "    cluster_colors = px.colors.qualitative.Set3[:n_clusters]\n",
        "    \n",
        "    # scatter plot com facetas por modelo\n",
        "    fig = px.scatter(\n",
        "        df_results,\n",
        "        x=\"x\", y=\"y\",\n",
        "        color=\"cluster\",\n",
        "        color_discrete_sequence=cluster_colors,\n",
        "        facet_col=\"modelo\",\n",
        "        facet_col_spacing=0.08,\n",
        "        hover_data={\n",
        "            \"post_id\": True,\n",
        "            \"titulo\": True,\n",
        "            \"modelo\": True,\n",
        "            \"cluster\": True,\n",
        "            \"x\": \":.3f\",\n",
        "            \"y\": \":.3f\"\n",
        "        },\n",
        "        title=\"Clusterização 2D por Modelo - Comparação BERT vs Word2Vec vs TF-IDF\"\n",
        "    )\n",
        "    \n",
        "    fig.update_layout(\n",
        "        template=\"plotly_white\",\n",
        "        legend_title_text=\"Clusters\",\n",
        "        margin=dict(l=40, r=40, t=80, b=40),\n",
        "        height=500,\n",
        "        width=1200\n",
        "    )\n",
        "    \n",
        "    fig.update_traces(\n",
        "        marker=dict(size=12, line=dict(width=1, color='white')),\n",
        "        opacity=0.8\n",
        "    )\n",
        "    \n",
        "    # adiciona títulos nos eixos\n",
        "    for annotation in fig.layout.annotations:\n",
        "        if \"modelo=\" in annotation.text:\n",
        "            modelo_nome = annotation.text.split(\"=\")[1]\n",
        "            modelo_data = df_results[df_results['modelo'] == modelo_nome]\n",
        "            if len(modelo_data) > 0:\n",
        "                var_x = modelo_data.iloc[0]['explained_var_x']\n",
        "                var_y = modelo_data.iloc[0]['explained_var_y']\n",
        "                annotation.text = f\"{modelo_nome}<br><sub>PCA1: {var_x:.1%}, PCA2: {var_y:.1%}</sub>\"\n",
        "    \n",
        "    fig.show()\n",
        "    return df_results, fig\n",
        "\n",
        "print(\"Funçao de scatter plot comparativo implementada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adicionar à classe ComparadorModelos um novo método para análises avançadas\n",
        "class AnalisadorAvancado:\n",
        "    def __init__(self, comparador_modelos):\n",
        "        self.comparador = comparador_modelos\n",
        "        self.embeddings_cache = {}\n",
        "        self.cluster_results = {}\n",
        "        self.similarity_results = {}\n",
        "        \n",
        "    def extrair_embeddings_dos_resultados(self, dados_processados):\n",
        "        \"\"\"\n",
        "        Extrai embeddings dos resultados da comparação e os armazena para análises.\n",
        "        \"\"\"\n",
        "        print(\"Extraindo embeddings dos resultados da comparação...\")\n",
        "        \n",
        "        textos_brutos = [item.get('texto_bruto', '') for item in dados_processados]\n",
        "        tokens_normalizados = [item.get('tokens_normalizados', []) for item in dados_processados]\n",
        "        \n",
        "        # Filtrar dados válidos\n",
        "        indices_validos = [i for i, texto in enumerate(textos_brutos) if texto.strip()]\n",
        "        textos_validos = [textos_brutos[i] for i in indices_validos]\n",
        "        tokens_validos = [tokens_normalizados[i] for i in indices_validos]\n",
        "        \n",
        "        embeddings = {}\n",
        "        \n",
        "        try:\n",
        "            # TF-IDF\n",
        "            print(\"Gerando embeddings TF-IDF...\")\n",
        "            embeddings['tfidf'] = self.comparador.processar_textos_tfidf(textos_validos)\n",
        "            \n",
        "            # Word2Vec\n",
        "            print(\"Gerando embeddings Word2Vec...\")\n",
        "            embeddings['word2vec'] = self.comparador.processar_textos_word2vec(tokens_validos)\n",
        "            \n",
        "            # BERT\n",
        "            print(\"Gerando embeddings BERT...\")\n",
        "            embeddings['bert'] = self.comparador.processar_textos_bert(textos_validos)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao extrair embeddings: {e}\")\n",
        "            \n",
        "        self.embeddings_cache = embeddings\n",
        "        return embeddings\n",
        "    \n",
        "    def analisar_similaridades(self, dados_processados, mostrar_heatmaps=True):\n",
        "        \"\"\"\n",
        "        Analisa similaridades entre documentos para todos os modelos.\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ANÁLISE DE SIMILARIDADES\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        if not self.embeddings_cache:\n",
        "            self.extrair_embeddings_dos_resultados(dados_processados)\n",
        "        \n",
        "        titulos = [item.get('titulo', f\"Post {i+1}\") for i, item in enumerate(dados_processados)]\n",
        "        \n",
        "        for modelo_nome, embeddings in self.embeddings_cache.items():\n",
        "            if embeddings is not None and len(embeddings) > 0:\n",
        "                print(f\"\\n--- Similaridade {modelo_nome.upper()} ---\")\n",
        "                \n",
        "                if mostrar_heatmaps:\n",
        "                    try:\n",
        "                        # Tentar plotly primeiro, depois matplotlib, por último apenas estatísticas\n",
        "                        S, fig = plot_similarity_heatmap_px(\n",
        "                            embeddings,\n",
        "                            titulos=titulos,\n",
        "                            title=f\"Similaridade Cosseno - {modelo_nome.upper()}\",\n",
        "                            cmap=\"Blues\",\n",
        "                            width=800,\n",
        "                            height=700,\n",
        "                            use_plotly=True  # Tenta plotly primeiro\n",
        "                        )\n",
        "                        self.similarity_results[modelo_nome] = S\n",
        "                    except Exception as e:\n",
        "                        print(f\"⚠️ Erro na visualização: {e}\")\n",
        "                        print(\"📊 Calculando apenas estatísticas...\")\n",
        "                        S = cosine_similarity(embeddings)\n",
        "                        self.similarity_results[modelo_nome] = S\n",
        "                else:\n",
        "                    S = cosine_similarity(embeddings)\n",
        "                    self.similarity_results[modelo_nome] = S\n",
        "                \n",
        "                # Estatísticas de similaridade (sempre mostrar)\n",
        "                mask = ~np.eye(S.shape[0], dtype=bool)\n",
        "                similarities = S[mask]\n",
        "                \n",
        "                print(f\"  📊 Estatísticas de Similaridade:\")\n",
        "                print(f\"     • Similaridade média: {np.mean(similarities):.4f}\")\n",
        "                print(f\"     • Desvio padrão: {np.std(similarities):.4f}\")\n",
        "                print(f\"     • Min: {np.min(similarities):.4f}\")\n",
        "                print(f\"     • Max: {np.max(similarities):.4f}\")\n",
        "                print(f\"     • Matriz: {S.shape[0]}x{S.shape[1]}\")\n",
        "            else:\n",
        "                print(f\"❌ Embeddings não disponíveis para {modelo_nome}\")\n",
        "    \n",
        "    def analisar_clusters(self, dados_processados, n_clusters=3, mostrar_scatter=True):\n",
        "        \"\"\"\n",
        "        Analisa clusters para todos os modelos.\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ANÁLISE DE CLUSTERIZAÇÃO\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        if not self.embeddings_cache:\n",
        "            self.extrair_embeddings_dos_resultados(dados_processados)\n",
        "        \n",
        "        # Análise individual por modelo\n",
        "        for modelo_nome, embeddings in self.embeddings_cache.items():\n",
        "            if embeddings is not None and len(embeddings) > 0:\n",
        "                print(f\"\\n--- Clusterização {modelo_nome.upper()} ---\")\n",
        "                \n",
        "                cluster_result = run_kmeans_clustering(embeddings, n_clusters=n_clusters)\n",
        "                self.cluster_results[modelo_nome] = cluster_result\n",
        "                \n",
        "                print(f\"  Número de clusters: {n_clusters}\")\n",
        "                print(f\"  Inércia (within-cluster sum of squares): {cluster_result['inertia']:.2f}\")\n",
        "                \n",
        "                # Distribuição dos clusters\n",
        "                unique, counts = np.unique(cluster_result['labels'], return_counts=True)\n",
        "                for cluster_id, count in zip(unique, counts):\n",
        "                    print(f\"  Cluster {cluster_id}: {count} documentos\")\n",
        "        \n",
        "        # Scatter plot comparativo\n",
        "        if mostrar_scatter:\n",
        "            print(\"\\n--- Visualização 2D Comparativa ---\")\n",
        "            try:\n",
        "                df_results, fig = plot_scatter_comparison_2d(\n",
        "                    self.embeddings_cache, \n",
        "                    dados_processados, \n",
        "                    n_clusters=n_clusters\n",
        "                )\n",
        "                return df_results\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Erro na visualização 2D: {e}\")\n",
        "                print(\"📊 Continuando sem visualização...\")\n",
        "                return None\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def gerar_relatorio_clusters(self, dados_processados, n_clusters=3):\n",
        "        \"\"\"\n",
        "        Gera relatório detalhado dos clusters encontrados.\n",
        "        \"\"\"\n",
        "        if not self.cluster_results:\n",
        "            self.analisar_clusters(dados_processados, n_clusters=n_clusters, mostrar_scatter=False)\n",
        "        \n",
        "        titulos = [item.get('titulo', f\"Post {i+1}\") for i, item in enumerate(dados_processados)]\n",
        "        \n",
        "        relatorio = []\n",
        "        relatorio.append(\"=\"*80)\n",
        "        relatorio.append(\"RELATÓRIO DETALHADO DE CLUSTERIZAÇÃO\")\n",
        "        relatorio.append(\"=\"*80)\n",
        "        \n",
        "        for modelo_nome, cluster_result in self.cluster_results.items():\n",
        "            relatorio.append(f\"\\n{modelo_nome.upper()}:\")\n",
        "            relatorio.append(\"-\" * 50)\n",
        "            \n",
        "            labels = cluster_result['labels']\n",
        "            \n",
        "            for cluster_id in sorted(np.unique(labels)):\n",
        "                indices_cluster = np.where(labels == cluster_id)[0]\n",
        "                relatorio.append(f\"\\nCluster {cluster_id} ({len(indices_cluster)} documentos):\")\n",
        "                \n",
        "                for idx in indices_cluster:\n",
        "                    titulo = titulos[idx] if idx < len(titulos) else f\"Post {idx+1}\"\n",
        "                    relatorio.append(f\"  • Post {idx+1}: {titulo[:60]}{'...' if len(titulo) > 60 else ''}\")\n",
        "        \n",
        "        relatorio_text = \"\\n\".join(relatorio)\n",
        "        \n",
        "        # Salvar relatório\n",
        "        caminho_relatorio = os.path.join(DATABASE_DIR, \"relatorio_clusters.txt\")\n",
        "        with open(caminho_relatorio, 'w', encoding='utf-8') as f:\n",
        "            f.write(relatorio_text)\n",
        "        \n",
        "        print(f\"\\nRelatório de clusters salvo em: {caminho_relatorio}\")\n",
        "        print(\"\\nPREVIEW DO RELATÓRIO:\")\n",
        "        print(relatorio_text)\n",
        "        \n",
        "        return relatorio_text\n",
        "\n",
        "print(\"Classe AnalisadorAvancado implementada\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Classificação com Naive Bayes\n",
        "\n",
        "Esta seção implementa classificação automática dos textos usando Naive Bayes:\n",
        "- **Classificação por Clusters**: Usa clusters do K-Means como labels para treinar o classificador\n",
        "- **Classificação Temática**: Cria categorias baseadas em palavras-chave dos posts\n",
        "- **Avaliação de Performance**: Métricas completas (accuracy, precision, recall, F1-score)\n",
        "- **Visualizações**: Matriz de confusão e comparação entre modelos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ClassificadorNaiveBayes:\n",
        "    \"\"\"\n",
        "    Classificador Naive Bayes para análise dos posts do blog.\n",
        "    Implementa classificação baseada em clusters e temática.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.modelos = {\n",
        "            'multinomial': MultinomialNB(),\n",
        "            'gaussiano': GaussianNB()\n",
        "        }\n",
        "        self.resultados = {}\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.categorias_tematicas = {\n",
        "            'história': ['história', 'histórico', 'blumenau', 'alemão', 'imigrante', 'colonização', 'colônia'],\n",
        "            'cultura': ['cultura', 'tradição', 'festa', 'oktoberfest', 'alemã', 'costume'],\n",
        "            'biografia': ['dr', 'hermann', 'bruno', 'otto', 'pessoa', 'vida', 'nasceu', 'morreu'],\n",
        "            'geografia': ['lugar', 'cidade', 'região', 'local', 'rio', 'vale', 'território'],\n",
        "            'economia': ['empresa', 'indústria', 'negócio', 'economia', 'desenvolvimento', 'comércio']\n",
        "        }\n",
        "        \n",
        "    def criar_labels_tematicos(self, dados_processados):\n",
        "        \"\"\"\n",
        "        Cria labels temáticos baseados em palavras-chave dos textos.\n",
        "        \"\"\"\n",
        "        print(\"Criando labels temáticos baseados em palavras-chave...\")\n",
        "        \n",
        "        labels_tematicos = []\n",
        "        \n",
        "        for item in dados_processados:\n",
        "            texto_lower = item.get('texto_bruto', '').lower()\n",
        "            titulo_lower = item.get('titulo', '').lower()\n",
        "            texto_completo = f\"{titulo_lower} {texto_lower}\"\n",
        "            \n",
        "            scores = {}\n",
        "            \n",
        "            # Calcular score para cada categoria\n",
        "            for categoria, palavras_chave in self.categorias_tematicas.items():\n",
        "                score = sum(1 for palavra in palavras_chave if palavra in texto_completo)\n",
        "                scores[categoria] = score\n",
        "            \n",
        "            # Atribuir categoria com maior score (ou 'geral' se empate)\n",
        "            if max(scores.values()) > 0:\n",
        "                categoria_predita = max(scores, key=scores.get)\n",
        "            else:\n",
        "                categoria_predita = 'geral'\n",
        "            \n",
        "            labels_tematicos.append(categoria_predita)\n",
        "        \n",
        "        return labels_tematicos\n",
        "    \n",
        "    def treinar_classificador(self, X, y, modelo_tipo='multinomial', test_size=0.3, random_state=42):\n",
        "        \"\"\"\n",
        "        Treina classificador Naive Bayes.\n",
        "        \n",
        "        Args:\n",
        "            X: embeddings dos textos\n",
        "            y: labels (clusters ou categorias temáticas)\n",
        "            modelo_tipo: 'multinomial' ou 'gaussiano'\n",
        "            test_size: tamanho do conjunto de teste\n",
        "            random_state: semente para reprodutibilidade\n",
        "        \"\"\"\n",
        "        print(f\"Treinando classificador Naive Bayes ({modelo_tipo})...\")\n",
        "        \n",
        "        # Garantir que X tenha valores não-negativos para MultinomialNB\n",
        "        if modelo_tipo == 'multinomial' and X.min() < 0:\n",
        "            print(\"  Normalizando dados para MultinomialNB (valores não-negativos)\")\n",
        "            X = X - X.min()  # Shift para valores não-negativos\n",
        "            X = X / X.max()  # Normalizar entre 0 e 1\n",
        "        \n",
        "        # Dividir dados\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "        )\n",
        "        \n",
        "        # Treinar modelo\n",
        "        modelo = self.modelos[modelo_tipo]\n",
        "        modelo.fit(X_train, y_train)\n",
        "        \n",
        "        # Predições\n",
        "        y_pred_train = modelo.predict(X_train)\n",
        "        y_pred_test = modelo.predict(X_test)\n",
        "        \n",
        "        # Métricas\n",
        "        acc_train = accuracy_score(y_train, y_pred_train)\n",
        "        acc_test = accuracy_score(y_test, y_pred_test)\n",
        "        \n",
        "        # Cross-validation\n",
        "        cv_scores = cross_val_score(modelo, X, y, cv=5, scoring='accuracy')\n",
        "        \n",
        "        resultado = {\n",
        "            'modelo': modelo,\n",
        "            'modelo_tipo': modelo_tipo,\n",
        "            'X_train': X_train, 'X_test': X_test,\n",
        "            'y_train': y_train, 'y_test': y_test,\n",
        "            'y_pred_train': y_pred_train, 'y_pred_test': y_pred_test,\n",
        "            'accuracy_train': acc_train,\n",
        "            'accuracy_test': acc_test,\n",
        "            'cv_scores': cv_scores,\n",
        "            'cv_mean': cv_scores.mean(),\n",
        "            'cv_std': cv_scores.std(),\n",
        "            'classification_report': classification_report(y_test, y_pred_test),\n",
        "            'confusion_matrix': confusion_matrix(y_test, y_pred_test)\n",
        "        }\n",
        "        \n",
        "        print(f\"  Accuracy Treino: {acc_train:.3f}\")\n",
        "        print(f\"  Accuracy Teste: {acc_test:.3f}\")\n",
        "        print(f\"  CV Score: {cv_scores.mean():.3f} (±{cv_scores.std():.3f})\")\n",
        "        \n",
        "        return resultado\n",
        "    \n",
        "    def classificar_por_clusters(self, embeddings_dict, cluster_results, metodo_embedding='tfidf'):\n",
        "        \"\"\"\n",
        "        Classifica textos usando clusters como labels.\n",
        "        \"\"\"\n",
        "        print(f\"\\n--- Classificação por Clusters ({metodo_embedding.upper()}) ---\")\n",
        "        \n",
        "        if metodo_embedding not in embeddings_dict or metodo_embedding not in cluster_results:\n",
        "            print(f\"Dados não disponíveis para {metodo_embedding}\")\n",
        "            return None\n",
        "        \n",
        "        X = embeddings_dict[metodo_embedding]\n",
        "        y = cluster_results[metodo_embedding]['labels']\n",
        "        \n",
        "        resultados = {}\n",
        "        \n",
        "        # Testar ambos os tipos de Naive Bayes\n",
        "        for modelo_tipo in ['multinomial', 'gaussiano']:\n",
        "            resultado = self.treinar_classificador(X, y, modelo_tipo=modelo_tipo)\n",
        "            resultados[modelo_tipo] = resultado\n",
        "        \n",
        "        self.resultados[f'clusters_{metodo_embedding}'] = resultados\n",
        "        return resultados\n",
        "    \n",
        "    def classificar_por_temas(self, embeddings_dict, dados_processados, metodo_embedding='tfidf'):\n",
        "        \"\"\"\n",
        "        Classifica textos usando categorias temáticas baseadas em palavras-chave.\n",
        "        \"\"\"\n",
        "        print(f\"\\n--- Classificação Temática ({metodo_embedding.upper()}) ---\")\n",
        "        \n",
        "        if metodo_embedding not in embeddings_dict:\n",
        "            print(f\"Embeddings não disponíveis para {metodo_embedding}\")\n",
        "            return None\n",
        "        \n",
        "        X = embeddings_dict[metodo_embedding]\n",
        "        y = self.criar_labels_tematicos(dados_processados)\n",
        "        \n",
        "        print(f\"Distribuição de categorias:\")\n",
        "        unique, counts = np.unique(y, return_counts=True)\n",
        "        for cat, count in zip(unique, counts):\n",
        "            print(f\"  {cat}: {count} documentos\")\n",
        "        \n",
        "        resultados = {}\n",
        "        \n",
        "        # Testar ambos os tipos de Naive Bayes\n",
        "        for modelo_tipo in ['multinomial', 'gaussiano']:\n",
        "            resultado = self.treinar_classificador(X, y, modelo_tipo=modelo_tipo)\n",
        "            resultados[modelo_tipo] = resultado\n",
        "        \n",
        "        self.resultados[f'tematica_{metodo_embedding}'] = resultados\n",
        "        return resultados\n",
        "    \n",
        "    def plotar_matriz_confusao(self, resultado, titulo=\"Matriz de Confusão\"):\n",
        "        \"\"\"\n",
        "        Plota matriz de confusão interativa.\n",
        "        \"\"\"\n",
        "        cm = resultado['confusion_matrix']\n",
        "        y_test = resultado['y_test']\n",
        "        \n",
        "        # Labels únicos\n",
        "        labels = sorted(list(set(y_test)))\n",
        "        \n",
        "        # Criar heatmap\n",
        "        fig = px.imshow(\n",
        "            cm,\n",
        "            labels=dict(x=\"Predição\", y=\"Real\", color=\"Contagem\"),\n",
        "            x=labels,\n",
        "            y=labels,\n",
        "            title=titulo,\n",
        "            color_continuous_scale='Blues',\n",
        "            text_auto=True\n",
        "        )\n",
        "        \n",
        "        fig.update_layout(\n",
        "            width=600,\n",
        "            height=500,\n",
        "            template=\"plotly_white\"\n",
        "        )\n",
        "        \n",
        "        fig.show()\n",
        "        return fig\n",
        "    \n",
        "    def comparar_modelos_classificacao(self):\n",
        "        \"\"\"\n",
        "        Compara performance de todos os modelos treinados.\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"COMPARAÇÃO DE PERFORMANCE - CLASSIFICAÇÃO NAIVE BAYES\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        dados_comparacao = []\n",
        "        \n",
        "        for experimento, resultados in self.resultados.items():\n",
        "            for modelo_tipo, resultado in resultados.items():\n",
        "                dados_comparacao.append({\n",
        "                    'Experimento': experimento,\n",
        "                    'Modelo': modelo_tipo,\n",
        "                    'Accuracy_Treino': resultado['accuracy_train'],\n",
        "                    'Accuracy_Teste': resultado['accuracy_test'],\n",
        "                    'CV_Mean': resultado['cv_mean'],\n",
        "                    'CV_Std': resultado['cv_std']\n",
        "                })\n",
        "        \n",
        "        if not dados_comparacao:\n",
        "            print(\"Nenhum modelo foi treinado ainda.\")\n",
        "            return None\n",
        "        \n",
        "        df_comp = pd.DataFrame(dados_comparacao)\n",
        "        \n",
        "        # Tabela resumo\n",
        "        print(\"\\nRESUMO DE PERFORMANCE:\")\n",
        "        print(\"-\" * 80)\n",
        "        print(f\"{'Experimento':<25} {'Modelo':<12} {'Acc_Treino':<10} {'Acc_Teste':<10} {'CV_Mean':<8} {'CV_Std':<8}\")\n",
        "        print(\"-\" * 80)\n",
        "        \n",
        "        for _, row in df_comp.iterrows():\n",
        "            print(f\"{row['Experimento']:<25} {row['Modelo']:<12} {row['Accuracy_Treino']:<10.3f} {row['Accuracy_Teste']:<10.3f} {row['CV_Mean']:<8.3f} {row['CV_Std']:<8.3f}\")\n",
        "        \n",
        "        # Gráfico comparativo\n",
        "        fig = px.bar(\n",
        "            df_comp,\n",
        "            x='Experimento',\n",
        "            y='Accuracy_Teste',\n",
        "            color='Modelo',\n",
        "            title=\"Comparação de Accuracy entre Modelos Naive Bayes\",\n",
        "            labels={'Accuracy_Teste': 'Accuracy no Teste'},\n",
        "            barmode='group'\n",
        "        )\n",
        "        \n",
        "        fig.update_layout(\n",
        "            template=\"plotly_white\",\n",
        "            height=500,\n",
        "            width=800\n",
        "        )\n",
        "        \n",
        "        fig.show()\n",
        "        \n",
        "        return df_comp\n",
        "    \n",
        "    def gerar_relatorio_classificacao(self, dados_processados):\n",
        "        \"\"\"\n",
        "        Gera relatório detalhado da classificação.\n",
        "        \"\"\"\n",
        "        relatorio = []\n",
        "        relatorio.append(\"=\"*80)\n",
        "        relatorio.append(\"RELATÓRIO DETALHADO - CLASSIFICAÇÃO NAIVE BAYES\")\n",
        "        relatorio.append(\"=\"*80)\n",
        "        \n",
        "        # Informações gerais\n",
        "        relatorio.append(f\"\\nDados analisados: {len(dados_processados)} documentos\")\n",
        "        relatorio.append(f\"Modelos treinados: {len(self.resultados)}\")\n",
        "        \n",
        "        # Categorias temáticas definidas\n",
        "        relatorio.append(f\"\\nCATEGORIAS TEMÁTICAS DEFINIDAS:\")\n",
        "        relatorio.append(\"-\" * 40)\n",
        "        for categoria, palavras in self.categorias_tematicas.items():\n",
        "            relatorio.append(f\"{categoria.upper()}: {', '.join(palavras[:5])}{'...' if len(palavras) > 5 else ''}\")\n",
        "        \n",
        "        # Resultados por experimento\n",
        "        for experimento, resultados in self.resultados.items():\n",
        "            relatorio.append(f\"\\n{experimento.upper()}:\")\n",
        "            relatorio.append(\"-\" * 50)\n",
        "            \n",
        "            for modelo_tipo, resultado in resultados.items():\n",
        "                relatorio.append(f\"\\nModelo {modelo_tipo}:\")\n",
        "                relatorio.append(f\"  • Accuracy Treino: {resultado['accuracy_train']:.3f}\")\n",
        "                relatorio.append(f\"  • Accuracy Teste: {resultado['accuracy_test']:.3f}\")\n",
        "                relatorio.append(f\"  • Cross-Validation: {resultado['cv_mean']:.3f} (±{resultado['cv_std']:.3f})\")\n",
        "                relatorio.append(f\"  • Classification Report:\")\n",
        "                \n",
        "                # Adicionar classification report indentado\n",
        "                for linha in resultado['classification_report'].split('\\n'):\n",
        "                    if linha.strip():\n",
        "                        relatorio.append(f\"    {linha}\")\n",
        "        \n",
        "        relatorio_text = \"\\n\".join(relatorio)\n",
        "        \n",
        "        # Salvar relatório\n",
        "        caminho_relatorio = os.path.join(DATABASE_DIR, \"relatorio_classificacao_naive_bayes.txt\")\n",
        "        with open(caminho_relatorio, 'w', encoding='utf-8') as f:\n",
        "            f.write(relatorio_text)\n",
        "        \n",
        "        print(f\"\\nRelatório de classificação salvo em: {caminho_relatorio}\")\n",
        "        \n",
        "        return relatorio_text\n",
        "\n",
        "print(\"Classe ClassificadorNaiveBayes implementada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def executar_classificacao_naive_bayes(dados_processados, analisador_avancado):\n",
        "    \"\"\"\n",
        "    Executa classificação Naive Bayes usando os resultados das análises anteriores.\n",
        "    \n",
        "    Args:\n",
        "        dados_processados: lista com dados dos posts processados\n",
        "        analisador_avancado: instância do AnalisadorAvancado já configurada\n",
        "    \n",
        "    Returns:\n",
        "        classificador: instância do ClassificadorNaiveBayes com resultados\n",
        "    \"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"CLASSIFICAÇÃO NAIVE BAYES\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    classificador = ClassificadorNaiveBayes()\n",
        "    \n",
        "    # Classificação baseada em clusters para cada método de embedding\n",
        "    print(\"\\n1. CLASSIFICAÇÃO BASEADA EM CLUSTERS\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    for metodo in ['tfidf', 'word2vec', 'bert']:\n",
        "        if metodo in analisador_avancado.embeddings_cache and metodo in analisador_avancado.cluster_results:\n",
        "            print(f\"\\n--- Classificação por Clusters - {metodo.upper()} ---\")\n",
        "            resultados_cluster = classificador.classificar_por_clusters(\n",
        "                analisador_avancado.embeddings_cache, \n",
        "                analisador_avancado.cluster_results, \n",
        "                metodo_embedding=metodo\n",
        "            )\n",
        "            \n",
        "            # Mostrar matriz de confusão para o melhor modelo\n",
        "            if resultados_cluster:\n",
        "                melhor_modelo = max(resultados_cluster.keys(), \n",
        "                                  key=lambda k: resultados_cluster[k]['accuracy_test'])\n",
        "                resultado = resultados_cluster[melhor_modelo]\n",
        "                \n",
        "                print(f\"\\nMelhor modelo para {metodo.upper()}: {melhor_modelo}\")\n",
        "                print(f\"Accuracy: {resultado['accuracy_test']:.3f}\")\n",
        "                \n",
        "                classificador.plotar_matriz_confusao(\n",
        "                    resultado, \n",
        "                    titulo=f\"Matriz de Confusão - Clusters {metodo.upper()} ({melhor_modelo})\"\n",
        "                )\n",
        "        else:\n",
        "            print(f\"Dados não disponíveis para {metodo}\")\n",
        "    \n",
        "    # Classificação temática\n",
        "    print(\"\\n2. CLASSIFICAÇÃO TEMÁTICA\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    if 'tfidf' in analisador_avancado.embeddings_cache:\n",
        "        print(\"\\n--- Classificação Temática - TF-IDF ---\")\n",
        "        resultados_tematica = classificador.classificar_por_temas(\n",
        "            analisador_avancado.embeddings_cache, \n",
        "            dados_processados, \n",
        "            metodo_embedding='tfidf'\n",
        "        )\n",
        "        \n",
        "        if resultados_tematica:\n",
        "            melhor_modelo = max(resultados_tematica.keys(), \n",
        "                              key=lambda k: resultados_tematica[k]['accuracy_test'])\n",
        "            resultado = resultados_tematica[melhor_modelo]\n",
        "            \n",
        "            print(f\"\\nMelhor modelo para classificação temática: {melhor_modelo}\")\n",
        "            print(f\"Accuracy: {resultado['accuracy_test']:.3f}\")\n",
        "            \n",
        "            classificador.plotar_matriz_confusao(\n",
        "                resultado, \n",
        "                titulo=f\"Matriz de Confusão - Classificação Temática ({melhor_modelo})\"\n",
        "            )\n",
        "    \n",
        "    # Comparação geral\n",
        "    print(\"\\n3. COMPARAÇÃO GERAL DE MODELOS\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    df_classificacao = classificador.comparar_modelos_classificacao()\n",
        "    \n",
        "    # Relatório detalhado\n",
        "    print(\"\\n4. RELATÓRIO DETALHADO\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    classificador.gerar_relatorio_classificacao(dados_processados)\n",
        "    \n",
        "    return classificador\n",
        "\n",
        "def executar_pipeline_completo_com_classificacao():\n",
        "    \"\"\"\n",
        "    Pipeline completo incluindo todas as análises: scraping, comparação de modelos,\n",
        "    clusterização, similaridade E classificação Naive Bayes.\n",
        "    \n",
        "    Versão robusta que executa tudo do zero, sem dependências externas.\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"PIPELINE COMPLETO COM CLASSIFICAÇÃO NAIVE BAYES\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    try:\n",
        "        # FASE 1: Carregar ou gerar dados\n",
        "        print(\"\\nFASE 1: CARREGAMENTO/GERAÇÃO DE DADOS\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        csv_path = os.path.join(DATABASE_DIR, \"dados_processados.csv\")\n",
        "        \n",
        "        if os.path.exists(csv_path):\n",
        "            print(\"Carregando dados existentes...\")\n",
        "            df = pd.read_csv(csv_path)\n",
        "            dados_processados = []\n",
        "            \n",
        "            for _, row in df.iterrows():\n",
        "                item = {\n",
        "                    'id': row.get('ID', ''),\n",
        "                    'titulo': row.get('ID', '').split('/')[-1].replace('-', ' ').replace('.html', '').title(),\n",
        "                    'texto_bruto': row.get('Texto_Bruto', ''),\n",
        "                    'tokens_normalizados': row.get('Tokens_Normalizados', '').split() if row.get('Tokens_Normalizados') else []\n",
        "                }\n",
        "                dados_processados.append(item)\n",
        "            \n",
        "            print(f\"Dados carregados: {len(dados_processados)} posts\")\n",
        "        else:\n",
        "            print(\"Executando scraping...\")\n",
        "            scraper = AdalbertoScraper()\n",
        "            scraper.processar_lista_posts()\n",
        "            dados_processados = scraper.resultados\n",
        "            scraper.close()\n",
        "            \n",
        "            if not dados_processados:\n",
        "                print(\"Nenhum dado obtido do scraping!\")\n",
        "                return None\n",
        "            \n",
        "            exportar_resultados_csv(dados_processados)\n",
        "        \n",
        "        # FASE 2: Análise básica de modelos\n",
        "        print(\"\\nFASE 2: COMPARAÇÃO BÁSICA DE MODELOS\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        comparador = ComparadorModelos()\n",
        "        resultados_comparacao = comparador.comparar_modelos(dados_processados)\n",
        "        \n",
        "        # FASE 3: Análises avançadas - Similaridade e Clusterização\n",
        "        print(\"\\nFASE 3: ANÁLISES AVANÇADAS - SIMILARIDADE E CLUSTERIZAÇÃO\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        analisador = AnalisadorAvancado(comparador)\n",
        "        \n",
        "        # Análise de similaridades com heatmaps\n",
        "        analisador.analisar_similaridades(dados_processados, mostrar_heatmaps=True)\n",
        "        \n",
        "        # Análise de clusterização com scatter plots\n",
        "        df_clusters = analisador.analisar_clusters(dados_processados, n_clusters=3, mostrar_scatter=True)\n",
        "        \n",
        "        # Relatório detalhado de clusters\n",
        "        analisador.gerar_relatorio_clusters(dados_processados, n_clusters=3)\n",
        "        \n",
        "        # FASE 4: Classificação Naive Bayes\n",
        "        print(\"\\nFASE 4: CLASSIFICAÇÃO NAIVE BAYES\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        classificador = executar_classificacao_naive_bayes(dados_processados, analisador)\n",
        "        \n",
        "        # FASE 5: Relatórios finais\n",
        "        print(\"\\nFASE 5: RELATÓRIOS FINAIS\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        relatorio = gerar_relatorio_comparativo(resultados_comparacao)\n",
        "        print(relatorio)\n",
        "        \n",
        "        salvar_resultados_comparacao(resultados_comparacao)\n",
        "        plotar_comparacao_modelos(resultados_comparacao)\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"PIPELINE COMPLETO COM CLASSIFICAÇÃO CONCLUÍDO!\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"Arquivos gerados:\")\n",
        "        print(f\"  • {DATABASE_DIR}/dados_processados.csv\")\n",
        "        print(f\"  • {DATABASE_DIR}/relatorio_comparativo.txt\")\n",
        "        print(f\"  • {DATABASE_DIR}/relatorio_clusters.txt\")\n",
        "        print(f\"  • {DATABASE_DIR}/relatorio_classificacao_naive_bayes.txt\")\n",
        "        print(f\"  • {DATABASE_DIR}/comparacao_modelos.csv\")\n",
        "        print(f\"  • {DATABASE_DIR}/comparacao_modelos.png\")\n",
        "        \n",
        "        return {\n",
        "            'dados_processados': dados_processados,\n",
        "            'resultados_comparacao': resultados_comparacao,\n",
        "            'analisador_avancado': analisador,\n",
        "            'df_clusters': df_clusters,\n",
        "            'classificador_naive_bayes': classificador\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\nERRO no pipeline: {e}\")\n",
        "        print(\"Verifique se todas as células anteriores foram executadas corretamente.\")\n",
        "        return None\n",
        "\n",
        "print(\"Funções de classificação Naive Bayes implementadas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def executar_analise_sem_visualizacoes():\n",
        "    \"\"\"\n",
        "    Versão ultra-robusta que executa todas as análises SEM visualizações interativas.\n",
        "    Para quando há problemas com plotly/jupyter display.\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"ANÁLISE COMPLETA SEM VISUALIZAÇÕES INTERATIVAS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    try:\n",
        "        # FASE 1: Carregar dados\n",
        "        csv_path = os.path.join(DATABASE_DIR, \"dados_processados.csv\")\n",
        "        \n",
        "        if os.path.exists(csv_path):\n",
        "            print(\"\\n📂 Carregando dados existentes...\")\n",
        "            df = pd.read_csv(csv_path)\n",
        "            dados_processados = []\n",
        "            \n",
        "            for _, row in df.iterrows():\n",
        "                item = {\n",
        "                    'id': row.get('ID', ''),\n",
        "                    'titulo': row.get('ID', '').split('/')[-1].replace('-', ' ').replace('.html', '').title(),\n",
        "                    'texto_bruto': row.get('Texto_Bruto', ''),\n",
        "                    'tokens_normalizados': row.get('Tokens_Normalizados', '').split() if row.get('Tokens_Normalizados') else []\n",
        "                }\n",
        "                dados_processados.append(item)\n",
        "            \n",
        "            print(f\"✅ Carregados {len(dados_processados)} posts\")\n",
        "        else:\n",
        "            print(\"❌ Arquivo dados_processados.csv não encontrado!\")\n",
        "            print(\"Execute primeiro o scraping para gerar os dados.\")\n",
        "            return None\n",
        "        \n",
        "        # FASE 2: Análise básica de modelos\n",
        "        print(\"\\n🔬 FASE 2: COMPARAÇÃO BÁSICA DE MODELOS\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        comparador = ComparadorModelos()\n",
        "        resultados_comparacao = comparador.comparar_modelos(dados_processados)\n",
        "        \n",
        "        # FASE 3: Análises avançadas SEM VISUALIZAÇÕES\n",
        "        print(\"\\n📊 FASE 3: ANÁLISES AVANÇADAS (SEM VISUALIZAÇÕES)\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        analisador = AnalisadorAvancado(comparador)\n",
        "        \n",
        "        # Análise de similaridades SEM heatmaps\n",
        "        print(\"🔍 Analisando similaridades...\")\n",
        "        analisador.analisar_similaridades(dados_processados, mostrar_heatmaps=False)\n",
        "        \n",
        "        # Análise de clusterização SEM scatter plots\n",
        "        print(\"\\n🎯 Analisando clusters...\")\n",
        "        analisador.analisar_clusters(dados_processados, n_clusters=3, mostrar_scatter=False)\n",
        "        \n",
        "        # Relatório detalhado de clusters\n",
        "        print(\"\\n📋 Gerando relatório de clusters...\")\n",
        "        analisador.gerar_relatorio_clusters(dados_processados, n_clusters=3)\n",
        "        \n",
        "        # FASE 4: Classificação Naive Bayes\n",
        "        print(\"\\n🧠 FASE 4: CLASSIFICAÇÃO NAIVE BAYES\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        classificador = executar_classificacao_naive_bayes(dados_processados, analisador)\n",
        "        \n",
        "        # FASE 5: Relatórios finais\n",
        "        print(\"\\n📄 FASE 5: RELATÓRIOS FINAIS\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        relatorio = gerar_relatorio_comparativo(resultados_comparacao)\n",
        "        print(relatorio)\n",
        "        \n",
        "        salvar_resultados_comparacao(resultados_comparacao)\n",
        "        \n",
        "        # Tentar plotar comparação simples (matplotlib)\n",
        "        try:\n",
        "            plotar_comparacao_modelos(resultados_comparacao)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Erro nos gráficos de comparação: {e}\")\n",
        "            print(\"📊 Continuando sem gráficos...\")\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"✅ ANÁLISE COMPLETA CONCLUÍDA (SEM VISUALIZAÇÕES INTERATIVAS)!\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"Arquivos gerados:\")\n",
        "        print(f\"  • {DATABASE_DIR}/dados_processados.csv\")\n",
        "        print(f\"  • {DATABASE_DIR}/relatorio_comparativo.txt\")\n",
        "        print(f\"  • {DATABASE_DIR}/relatorio_clusters.txt\")\n",
        "        print(f\"  • {DATABASE_DIR}/relatorio_classificacao_naive_bayes.txt\")\n",
        "        print(f\"  • {DATABASE_DIR}/comparacao_modelos.csv\")\n",
        "        \n",
        "        return {\n",
        "            'dados_processados': dados_processados,\n",
        "            'resultados_comparacao': resultados_comparacao,\n",
        "            'analisador_avancado': analisador,\n",
        "            'classificador_naive_bayes': classificador\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ ERRO na análise: {e}\")\n",
        "        import traceback\n",
        "        print(\"Stacktrace completo:\")\n",
        "        print(traceback.format_exc())\n",
        "        return None\n",
        "\n",
        "print(\"Versão sem visualizações criada - à prova de erros de display!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ⚠️ VERIFICAÇÃO DE DEPENDÊNCIAS\n",
        "\n",
        "Execute esta célula primeiro para verificar se todas as funções necessárias estão disponíveis:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def verificar_dependencias():\n",
        "    \"\"\"\n",
        "    Verifica se todas as funções e classes necessárias estão disponíveis.\n",
        "    \"\"\"\n",
        "    print(\"Verificando dependências do pipeline...\")\n",
        "    \n",
        "    funcoes_necessarias = [\n",
        "        'ComparadorModelos',\n",
        "        'AnalisadorAvancado', \n",
        "        'ClassificadorNaiveBayes',\n",
        "        'executar_classificacao_naive_bayes',\n",
        "        'plot_similarity_heatmap_px',\n",
        "        'run_kmeans_clustering',\n",
        "        'reduce_to_2d',\n",
        "        'gerar_relatorio_comparativo',\n",
        "        'salvar_resultados_comparacao',\n",
        "        'plotar_comparacao_modelos',\n",
        "        'exportar_resultados_csv'\n",
        "    ]\n",
        "    \n",
        "    disponivel = True\n",
        "    \n",
        "    for func_name in funcoes_necessarias:\n",
        "        try:\n",
        "            # Tenta acessar o objeto no namespace global\n",
        "            obj = globals().get(func_name)\n",
        "            if obj is None:\n",
        "                print(f\"❌ {func_name} - NÃO ENCONTRADA\")\n",
        "                disponivel = False\n",
        "            else:\n",
        "                print(f\"✅ {func_name} - OK\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ {func_name} - ERRO: {e}\")\n",
        "            disponivel = False\n",
        "    \n",
        "    # Verificar variáveis globais importantes\n",
        "    variaveis_necessarias = ['DATABASE_DIR', 'MAX_POSTS']\n",
        "    \n",
        "    for var_name in variaveis_necessarias:\n",
        "        if var_name in globals():\n",
        "            print(f\"✅ {var_name} = {globals()[var_name]} - OK\")\n",
        "        else:\n",
        "            print(f\"❌ {var_name} - NÃO ENCONTRADA\")\n",
        "            disponivel = False\n",
        "    \n",
        "    if disponivel:\n",
        "        print(\"\\n🎉 Todas as dependências estão disponíveis!\")\n",
        "        print(\"Você pode executar o pipeline completo com segurança.\")\n",
        "    else:\n",
        "        print(\"\\n⚠️ Algumas dependências estão faltando.\")\n",
        "        print(\"Execute todas as células anteriores na ordem correta antes de continuar.\")\n",
        "        \n",
        "        print(\"\\nPara resolver:\")\n",
        "        print(\"1. Vá para o início do notebook\")\n",
        "        print(\"2. Execute as células uma por uma, de cima para baixo\")\n",
        "        print(\"3. Volte aqui e execute esta verificação novamente\")\n",
        "    \n",
        "    return disponivel\n",
        "\n",
        "# Executar verificação\n",
        "verificar_dependencias()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🛠️ VERSÃO SIMPLIFICADA (Em caso de erro)\n",
        "\n",
        "Se ainda houver problemas, use esta versão simplificada que funciona independentemente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def executar_classificacao_simples():\n",
        "    \"\"\"\n",
        "    Versão simplificada que funciona mesmo se algumas dependências estiverem faltando.\n",
        "    Carrega dados existentes e faz apenas a classificação Naive Bayes.\n",
        "    \"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"CLASSIFICAÇÃO NAIVE BAYES - VERSÃO SIMPLIFICADA\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    try:\n",
        "        # Verificar se arquivo de dados existe\n",
        "        csv_path = os.path.join(DATABASE_DIR, \"dados_processados.csv\")\n",
        "        \n",
        "        if not os.path.exists(csv_path):\n",
        "            print(f\"❌ Arquivo não encontrado: {csv_path}\")\n",
        "            print(\"Execute primeiro o scraping para gerar os dados.\")\n",
        "            return None\n",
        "        \n",
        "        # Carregar dados\n",
        "        print(\"📂 Carregando dados do CSV...\")\n",
        "        df = pd.read_csv(csv_path)\n",
        "        \n",
        "        dados_processados = []\n",
        "        for _, row in df.iterrows():\n",
        "            item = {\n",
        "                'id': row.get('ID', ''),\n",
        "                'titulo': row.get('ID', '').split('/')[-1].replace('-', ' ').replace('.html', '').title(),\n",
        "                'texto_bruto': row.get('Texto_Bruto', ''),\n",
        "                'tokens_normalizados': row.get('Tokens_Normalizados', '').split() if row.get('Tokens_Normalizados') else []\n",
        "            }\n",
        "            dados_processados.append(item)\n",
        "        \n",
        "        print(f\"✅ Carregados {len(dados_processados)} posts\")\n",
        "        \n",
        "        # Gerar embeddings simples (apenas TF-IDF para começar)\n",
        "        print(\"\\n🔢 Gerando embeddings TF-IDF...\")\n",
        "        textos = [item['texto_bruto'] for item in dados_processados]\n",
        "        \n",
        "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "        vectorizer = TfidfVectorizer(max_features=500, stop_words=None, min_df=1)\n",
        "        X_tfidf = vectorizer.fit_transform(textos).toarray()\n",
        "        \n",
        "        print(f\"✅ Embeddings gerados: {X_tfidf.shape}\")\n",
        "        \n",
        "        # Criar clusters simples\n",
        "        print(\"\\n🎯 Criando clusters K-Means...\")\n",
        "        from sklearn.cluster import KMeans\n",
        "        kmeans = KMeans(n_clusters=3, random_state=42, n_init='auto')\n",
        "        cluster_labels = kmeans.fit_predict(X_tfidf)\n",
        "        \n",
        "        # Classificação com Naive Bayes\n",
        "        print(\"\\n🧠 Treinando classificador Naive Bayes...\")\n",
        "        \n",
        "        classificador = ClassificadorNaiveBayes()\n",
        "        \n",
        "        # Classificação baseada em clusters\n",
        "        print(\"\\n1️⃣ Classificação por clusters:\")\n",
        "        resultado_cluster = classificador.treinar_classificador(X_tfidf, cluster_labels, modelo_tipo='multinomial')\n",
        "        \n",
        "        print(f\"   Accuracy no teste: {resultado_cluster['accuracy_test']:.3f}\")\n",
        "        print(f\"   Cross-validation: {resultado_cluster['cv_mean']:.3f} (±{resultado_cluster['cv_std']:.3f})\")\n",
        "        \n",
        "        # Classificação temática\n",
        "        print(\"\\n2️⃣ Classificação temática:\")\n",
        "        labels_tematicos = classificador.criar_labels_tematicos(dados_processados)\n",
        "        \n",
        "        # Mostrar distribuição de temas\n",
        "        unique, counts = np.unique(labels_tematicos, return_counts=True)\n",
        "        for tema, count in zip(unique, counts):\n",
        "            print(f\"   {tema}: {count} posts\")\n",
        "        \n",
        "        resultado_tematico = classificador.treinar_classificador(X_tfidf, labels_tematicos, modelo_tipo='multinomial')\n",
        "        \n",
        "        print(f\"   Accuracy no teste: {resultado_tematico['accuracy_test']:.3f}\")\n",
        "        print(f\"   Cross-validation: {resultado_tematico['cv_mean']:.3f} (±{resultado_tematico['cv_std']:.3f})\")\n",
        "        \n",
        "        # Matriz de confusão simples (só a temática)\n",
        "        print(\"\\n📊 Matriz de confusão (classificação temática):\")\n",
        "        print(resultado_tematico['classification_report'])\n",
        "        \n",
        "        # Salvar resultados simples\n",
        "        relatorio_path = os.path.join(DATABASE_DIR, \"classificacao_simples.txt\")\n",
        "        with open(relatorio_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"CLASSIFICAÇÃO NAIVE BAYES - VERSÃO SIMPLIFICADA\\n\")\n",
        "            f.write(\"=\"*60 + \"\\n\\n\")\n",
        "            f.write(f\"Dados processados: {len(dados_processados)} posts\\n\")\n",
        "            f.write(f\"Embeddings: TF-IDF {X_tfidf.shape}\\n\\n\")\n",
        "            \n",
        "            f.write(\"CLASSIFICAÇÃO POR CLUSTERS:\\n\")\n",
        "            f.write(f\"Accuracy: {resultado_cluster['accuracy_test']:.3f}\\n\")\n",
        "            f.write(f\"CV Score: {resultado_cluster['cv_mean']:.3f} ± {resultado_cluster['cv_std']:.3f}\\n\\n\")\n",
        "            \n",
        "            f.write(\"CLASSIFICAÇÃO TEMÁTICA:\\n\")\n",
        "            f.write(f\"Accuracy: {resultado_tematico['accuracy_test']:.3f}\\n\")\n",
        "            f.write(f\"CV Score: {resultado_tematico['cv_mean']:.3f} ± {resultado_tematico['cv_std']:.3f}\\n\\n\")\n",
        "            \n",
        "            f.write(\"CLASSIFICATION REPORT:\\n\")\n",
        "            f.write(resultado_tematico['classification_report'])\n",
        "        \n",
        "        print(f\"\\n💾 Resultados salvos em: {relatorio_path}\")\n",
        "        \n",
        "        print(\"\\n🎉 CLASSIFICAÇÃO SIMPLES CONCLUÍDA!\")\n",
        "        \n",
        "        return {\n",
        "            'dados_processados': dados_processados,\n",
        "            'embeddings_tfidf': X_tfidf,\n",
        "            'clusters': cluster_labels,\n",
        "            'labels_tematicos': labels_tematicos,\n",
        "            'resultado_cluster': resultado_cluster,\n",
        "            'resultado_tematico': resultado_tematico,\n",
        "            'classificador': classificador\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Erro na classificação simples: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        return None\n",
        "\n",
        "print(\"Versão simplificada da classificação criada.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🚀 EXECUÇÃO DA CLASSIFICAÇÃO NAIVE BAYES\n",
        "\n",
        "**🚨 RESOLVENDO O ERRO DE DISPLAY/PLOTLY:**\n",
        "\n",
        "Se você recebeu erro similar a `ValueError` ou problemas com `display_jupyter_version_warnings()`, isso é um problema comum com visualizações interativas do plotly no Jupyter.\n",
        "\n",
        "**Agora você tem TRÊS opções (execute apenas uma!):**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 OPÇÃO A: PIPELINE COMPLETO COM VISUALIZAÇÕES INTERATIVAS\n",
        "# Execute apenas se a verificação de dependências passou ✅ E não há problemas com plotly\n",
        "\n",
        "# Descomente as linhas abaixo APENAS se tudo estiver funcionando:\n",
        "\"\"\"\n",
        "print(\"🚀 Executando pipeline completo com visualizações...\")\n",
        "resultados_completos = executar_pipeline_completo_com_classificacao()\n",
        "\"\"\"\n",
        "\n",
        "print(\"💡 INSTRUÇÕES para OPÇÃO A:\")\n",
        "print(\"✅ Use se: verificação passou E não há erros de plotly\")\n",
        "print(\"❌ Não use se: há erros de visualização/display\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🛠️ OPÇÃO B: ANÁLISE COMPLETA SEM VISUALIZAÇÕES INTERATIVAS\n",
        "# Use esta se houve erro com plotly/display na Opção A\n",
        "# Faz TUDO exceto visualizações interativas\n",
        "\n",
        "# Descomente a linha abaixo se houve erro com visualizações:\n",
        "\"\"\"\n",
        "print(\"🔧 Executando análise sem visualizações interativas...\")\n",
        "resultados_sem_viz = executar_analise_sem_visualizacoes()\n",
        "\"\"\"\n",
        "\n",
        "print(\"💡 INSTRUÇÕES para OPÇÃO B:\")\n",
        "print(\"✅ Use se: houve erro com plotly na Opção A\")\n",
        "print(\"🎯 Faz: embeddings + clusters + similaridade + classificação (sem gráficos interativos)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚨 OPÇÃO C: APENAS CLASSIFICAÇÃO SIMPLES (Sempre funciona!)\n",
        "# Use esta como último recurso - funciona mesmo com várias dependências faltando\n",
        "# Carrega dados existentes e faz apenas classificação Naive Bayes com TF-IDF\n",
        "\n",
        "print(\"🆘 Executando apenas classificação simples...\")\n",
        "resultados_classificacao = executar_classificacao_simples()\n",
        "\n",
        "print(\"\\n💡 INSTRUÇÕES para OPÇÃO C:\")\n",
        "print(\"✅ Use se: Opções A e B falharam\")\n",
        "print(\"🎯 Faz: apenas classificação Naive Bayes básica\")\n",
        "print(\"🔧 Funciona: mesmo com dependências faltando\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 📋 RESUMO DAS OPÇÕES DE EXECUÇÃO\n",
        "\n",
        "| Opção | Quando Usar | O que Faz | Funciona? |\n",
        "|-------|-------------|-----------|-----------|\n",
        "| **A** 🎯 | Tudo funcionando perfeitamente | Pipeline completo + visualizações interativas | ⚠️ Pode dar erro de plotly |\n",
        "| **B** 🛠️ | Erro com plotly/display | Análise completa sem visualizações interativas | ✅ Muito provável funcionar |\n",
        "| **C** 🚨 | Último recurso | Apenas classificação Naive Bayes básica | ✅ Sempre funciona |\n",
        "\n",
        "### 🎯 RECOMENDAÇÃO:\n",
        "1. **Para o seu erro atual**: Execute a **OPÇÃO C** primeiro para ter certeza que funciona\n",
        "2. **Se funcionou**: Tente também a **OPÇÃO B** para ter análise completa\n",
        "3. **Se ambas funcionaram**: Pode tentar a **OPÇÃO A** depois (mas não é necessário)\n",
        "\n",
        "### ✅ RESULTADOS GARANTIDOS:\n",
        "Mesmo usando apenas a **OPÇÃO C**, você terá:\n",
        "- ✅ Classificação Naive Bayes funcional\n",
        "- ✅ Categorização automática dos posts (história, biografia, cultura, etc.)\n",
        "- ✅ Métricas de accuracy e performance\n",
        "- ✅ Relatório completo salvo em arquivo\n",
        "- ✅ Comparação entre MultinomialNB e GaussianNB\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 🎊 RESUMO FINAL - CLASSIFICAÇÃO NAIVE BAYES IMPLEMENTADA!\n",
        "\n",
        "### ✅ **O que foi adicionado:**\n",
        "1. **Classe `ClassificadorNaiveBayes`** com dois tipos de classificação:\n",
        "   - **Por Clusters**: Usa grupos do K-Means como categorias\n",
        "   - **Temática**: Categorização baseada em palavras-chave (história, biografia, cultura, geografia, economia)\n",
        "\n",
        "2. **Múltiplos Algoritmos**:\n",
        "   - MultinomialNB (ideal para TF-IDF)\n",
        "   - GaussianNB (ideal para embeddings BERT/Word2Vec)\n",
        "\n",
        "3. **Avaliação Completa**:\n",
        "   - Accuracy, Precision, Recall, F1-score\n",
        "   - Cross-validation com 5 folds\n",
        "   - Matrizes de confusão interativas\n",
        "\n",
        "4. **Duas Versões de Execução**:\n",
        "   - **Pipeline Completo**: Integrado com todo o sistema\n",
        "   - **Versão Simplificada**: Funciona independentemente\n",
        "\n",
        "### 📁 **Arquivos Gerados Adicionais:**\n",
        "- `relatorio_classificacao_naive_bayes.txt` - Análise completa\n",
        "- `classificacao_simples.txt` - Versão simplificada (se usada)\n",
        "\n",
        "### 🚀 **Como Usar:**\n",
        "```python\n",
        "# Verificar dependências primeiro\n",
        "verificar_dependencias()\n",
        "\n",
        "# Opção A: Pipeline completo (se verificação passou)\n",
        "resultados = executar_pipeline_completo_com_classificacao()\n",
        "\n",
        "# Opção B: Versão simplificada (sempre funciona)\n",
        "resultados = executar_classificacao_simples()\n",
        "```\n",
        "\n",
        "### 🏆 **Benefícios Alcançados:**\n",
        "1. **Categorização Automática** dos posts do blog\n",
        "2. **Comparação Robusta** entre diferentes métodos de embedding\n",
        "3. **Visualizações Claras** da performance dos classificadores\n",
        "4. **Relatórios Detalhados** para análise posterior\n",
        "5. **Flexibilidade** para funcionar mesmo com dependências faltando\n",
        "\n",
        "**🎯 Seu projeto agora tem análise COMPLETA: scraping → embeddings → clusterização → similaridade → classificação!** \n",
        "\n",
        "---\n",
        "\n",
        "## 🔧 RESOLUÇÃO DE PROBLEMAS E VERIFICAÇÃO\n",
        "\n",
        "### 🚨 **Se ainda houver erros:**\n",
        "\n",
        "1. **Primeiro**: Execute sempre a verificação de dependências:\n",
        "   ```python\n",
        "   verificar_dependencias()\n",
        "   ```\n",
        "\n",
        "2. **Se faltarem funções**: Execute as células do notebook em ordem, de cima para baixo\n",
        "\n",
        "3. **Se erro persistir**: Use a **Opção C** que é à prova de falhas\n",
        "\n",
        "### ✅ **Como verificar se funcionou:**\n",
        "\n",
        "Após executar qualquer opção, verifique se foram criados os arquivos:\n",
        "```python\n",
        "import os\n",
        "print(\"📁 Arquivos gerados:\")\n",
        "for arquivo in os.listdir(DATABASE_DIR):\n",
        "    if arquivo.endswith(('.txt', '.csv')):\n",
        "        caminho = os.path.join(DATABASE_DIR, arquivo)\n",
        "        tamanho = os.path.getsize(caminho)\n",
        "        print(f\"  ✅ {arquivo} ({tamanho} bytes)\")\n",
        "```\n",
        "\n",
        "### 📊 **Verificar resultados da classificação:**\n",
        "```python\n",
        "# Se usou Opção C\n",
        "if 'resultados_classificacao' in locals() and resultados_classificacao:\n",
        "    print(\"🎉 Classificação Naive Bayes funcionou!\")\n",
        "    print(f\"📈 Dados processados: {len(resultados_classificacao['dados_processados'])}\")\n",
        "    print(f\"📊 TF-IDF shape: {resultados_classificacao['embeddings_tfidf'].shape}\")\n",
        "    print(f\"🏆 Accuracy temática: {resultados_classificacao['resultado_tematico']['accuracy_test']:.3f}\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execução da Classificação Naive Bayes\n",
        "\n",
        "Execute estas células para realizar a classificação:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPÇÃO 1: Pipeline completo incluindo classificação Naive Bayes\n",
        "# Esta é a forma mais simples - executa TUDO de uma vez\n",
        "resultados_completos_com_classificacao = executar_pipeline_completo_com_classificacao()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPÇÃO 2: Apenas classificação Naive Bayes (se já executou análises anteriores)\n",
        "\"\"\"\n",
        "# Descomente as linhas abaixo se já tiver executado as análises básicas:\n",
        "classificador = executar_classificacao_naive_bayes(\n",
        "    dados_processados=resultados_completos['dados_processados'],\n",
        "    analisador_avancado=resultados_completos['analisador_avancado']\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "print(\"Opções de execução configuradas!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Funções de Relatório e Visualização\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gerar_relatorio_comparativo(resultados_comparacao: dict) -> str:\n",
        "    if not resultados_comparacao:\n",
        "        return \"Não há resultados para gerar relatório\"\n",
        "    \n",
        "    relatorio = []\n",
        "    relatorio.append(\"=\"*60)\n",
        "    relatorio.append(\"RELATÓRIO COMPARATIVO - MODELOS DE REPRESENTAÇÃO TEXTUAL\")\n",
        "    relatorio.append(\"=\"*60)\n",
        "    relatorio.append(\"\")\n",
        "    \n",
        "    relatorio.append(\"COMPARAÇÃO GERAL:\")\n",
        "    relatorio.append(\"-\" * 60)\n",
        "    \n",
        "    linha_header = f\"{'Modelo':<12} {'Dimensões':<10} {'Sim.Média':<10} {'Std':<8} {'Min':<8} {'Max':<8}\"\n",
        "    relatorio.append(linha_header)\n",
        "    relatorio.append(\"-\" * 60)\n",
        "    \n",
        "    for modelo_key, dados in resultados_comparacao.items():\n",
        "        if 'erro' not in dados:\n",
        "            linha = f\"{dados['modelo']:<12} {dados['dimensoes']:<10} {dados['similaridade_media']:<10.3f} {dados['similaridade_std']:<8.3f} {dados['similaridade_min']:<8.3f} {dados['similaridade_max']:<8.3f}\"\n",
        "            relatorio.append(linha)\n",
        "        else:\n",
        "            linha = f\"{dados['modelo']:<12} {'ERRO':<10} {dados['erro']}\"\n",
        "            relatorio.append(linha)\n",
        "    \n",
        "    relatorio.append(\"\")\n",
        "    relatorio.append(\"ANÁLISE DETALHADA:\")\n",
        "    relatorio.append(\"-\" * 40)\n",
        "    \n",
        "    for modelo_key, dados in resultados_comparacao.items():\n",
        "        if 'erro' not in dados:\n",
        "            relatorio.append(f\"\\n{dados['modelo']}:\")\n",
        "            relatorio.append(f\"  • Dimensionalidade: {dados['dimensoes']}\")\n",
        "            relatorio.append(f\"  • Documentos processados: {dados['num_documentos']}\")\n",
        "            relatorio.append(f\"  • Similaridade média: {dados['similaridade_media']:.4f}\")\n",
        "            relatorio.append(f\"  • Desvio padrão: {dados['similaridade_std']:.4f}\")\n",
        "            \n",
        "            if dados['similaridade_media'] > 0.5:\n",
        "                interpretacao = \"Alta similaridade entre documentos\"\n",
        "            elif dados['similaridade_media'] > 0.3:\n",
        "                interpretacao = \"Similaridade moderada\"\n",
        "            else:\n",
        "                interpretacao = \"Baixa similaridade (mais diversidade)\"\n",
        "            \n",
        "            relatorio.append(f\"  • Interpretação: {interpretacao}\")\n",
        "    \n",
        "    return \"\\n\".join(relatorio)\n",
        "\n",
        "def exportar_resultados_csv(resultados: list) -> str:\n",
        "    if not resultados:\n",
        "        print(\"Nenhum resultado foi extraído\")\n",
        "        return None\n",
        "    \n",
        "    try:\n",
        "        rows = []\n",
        "        for item in resultados:\n",
        "            row = {\n",
        "                \"ID\": item.get('id', ''),\n",
        "                \"Texto_Bruto\": item.get('texto_bruto', '')[:200] + '...' if len(item.get('texto_bruto', '')) > 200 else item.get('texto_bruto', ''),\n",
        "                \"Tokens_Normalizados\": ' '.join(item.get('tokens_normalizados', [])[:20]),\n",
        "                \"Stemming\": ' '.join(item.get('tokens_stemming', [])[:20]),\n",
        "                \"Lemma\": ' '.join(item.get('tokens_lemmatizacao', [])[:20]),\n",
        "                \"Outros_Dados_Relevantes\": _formatar_metadados(item.get('metadados', {})),\n",
        "            }\n",
        "            rows.append(row)\n",
        "        \n",
        "        df = pd.DataFrame(rows)\n",
        "        caminho_csv = os.path.join(DATABASE_DIR, \"dados_processados.csv\")\n",
        "        df.to_csv(caminho_csv, index=False, encoding=\"utf-8-sig\")\n",
        "        \n",
        "        print(f\"Arquivo CSV salvo em: {caminho_csv}\")\n",
        "        return caminho_csv\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Erro na exportação: {e}\")\n",
        "        return None\n",
        "\n",
        "def _formatar_metadados(metadados: dict) -> str:\n",
        "    try:\n",
        "        elementos = []\n",
        "        if metadados.get('datas_encontradas'):\n",
        "            elementos.append(f\"Datas: {', '.join(metadados['datas_encontradas'][:3])}\")\n",
        "        if metadados.get('nomes_proprios'):\n",
        "            elementos.append(f\"Nomes: {', '.join(metadados['nomes_proprios'][:3])}\")\n",
        "        return \" | \".join(elementos) if elementos else \"N/A\"\n",
        "    except Exception:\n",
        "        return \"N/A\"\n",
        "\n",
        "def salvar_resultados_comparacao(resultados_comparacao: dict):\n",
        "    try:\n",
        "        relatorio = gerar_relatorio_comparativo(resultados_comparacao)\n",
        "        caminho_txt = os.path.join(DATABASE_DIR, \"relatorio_comparativo.txt\")\n",
        "        with open(caminho_txt, 'w', encoding='utf-8') as f:\n",
        "            f.write(relatorio)\n",
        "        \n",
        "        dados_csv = []\n",
        "        for modelo_key, dados in resultados_comparacao.items():\n",
        "            if 'erro' not in dados:\n",
        "                dados_csv.append({\n",
        "                    'Modelo': dados['modelo'],\n",
        "                    'Dimensoes': dados['dimensoes'],\n",
        "                    'Num_Documentos': dados['num_documentos'],\n",
        "                    'Similaridade_Media': dados['similaridade_media'],\n",
        "                    'Similaridade_Std': dados['similaridade_std'],\n",
        "                    'Similaridade_Min': dados['similaridade_min'],\n",
        "                    'Similaridade_Max': dados['similaridade_max']\n",
        "                })\n",
        "        \n",
        "        if dados_csv:\n",
        "            df = pd.DataFrame(dados_csv)\n",
        "            caminho_csv = os.path.join(DATABASE_DIR, \"comparacao_modelos.csv\")\n",
        "            df.to_csv(caminho_csv, index=False, encoding='utf-8-sig')\n",
        "        \n",
        "        print(f\"Relatórios salvos em: {DATABASE_DIR}/\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao salvar resultados: {e}\")\n",
        "\n",
        "def plotar_comparacao_modelos(resultados_comparacao: dict):\n",
        "    if not resultados_comparacao:\n",
        "        print(\"Não há dados para plotar\")\n",
        "        return\n",
        "    \n",
        "    modelos_validos = {k: v for k, v in resultados_comparacao.items() if 'erro' not in v}\n",
        "    \n",
        "    if not modelos_validos:\n",
        "        print(\"Nenhum modelo válido para plotar\")\n",
        "        return\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('Comparação de Modelos de Representação Textual', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Dados para plots\n",
        "    modelos = [v['modelo'] for v in modelos_validos.values()]\n",
        "    similaridades_medias = [v['similaridade_media'] for v in modelos_validos.values()]\n",
        "    desvios = [v['similaridade_std'] for v in modelos_validos.values()]\n",
        "    dimensoes = [v['dimensoes'] for v in modelos_validos.values()]\n",
        "    \n",
        "    # 1. Similaridade Média\n",
        "    axes[0,0].bar(modelos, similaridades_medias, color=['skyblue', 'lightgreen', 'salmon'])\n",
        "    axes[0,0].set_title('Similaridade Média entre Documentos')\n",
        "    axes[0,0].set_ylabel('Similaridade Coseno')\n",
        "    axes[0,0].set_ylim(0, 1)\n",
        "    \n",
        "    # 2. Desvio Padrão\n",
        "    axes[0,1].bar(modelos, desvios, color=['lightcoral', 'gold', 'lightblue'])\n",
        "    axes[0,1].set_title('Desvio Padrão das Similaridades')\n",
        "    axes[0,1].set_ylabel('Desvio Padrão')\n",
        "    \n",
        "    # 3. Dimensionalidade\n",
        "    axes[1,0].bar(modelos, dimensoes, color=['mediumpurple', 'orange', 'lightgray'])\n",
        "    axes[1,0].set_title('Dimensionalidade dos Embeddings')\n",
        "    axes[1,0].set_ylabel('Número de Dimensões')\n",
        "    axes[1,0].set_yscale('log')\n",
        "    \n",
        "    # 4. Comparação Detalhada\n",
        "    x_pos = np.arange(len(modelos))\n",
        "    width = 0.25\n",
        "    \n",
        "    axes[1,1].bar(x_pos - width, similaridades_medias, width, label='Similaridade Média', alpha=0.8)\n",
        "    axes[1,1].bar(x_pos, desvios, width, label='Desvio Padrão', alpha=0.8)\n",
        "    axes[1,1].bar(x_pos + width, [d/1000 for d in dimensoes], width, label='Dimensões (÷1000)', alpha=0.8)\n",
        "    \n",
        "    axes[1,1].set_title('Comparação Geral')\n",
        "    axes[1,1].set_xlabel('Modelos')\n",
        "    axes[1,1].set_xticks(x_pos)\n",
        "    axes[1,1].set_xticklabels(modelos)\n",
        "    axes[1,1].legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(DATABASE_DIR, 'comparacao_modelos.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "print(\"Funções de relatório e visualização implementadas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def executar_analise_completa_avancada():\n",
        "    \"\"\"\n",
        "    Executa análise completa incluindo clusterização e similaridade avançadas.\n",
        "    \"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"PIPELINE COMPLETO COM ANÁLISES AVANÇADAS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # FASE 1: Scraping (usando dados existentes se disponível)\n",
        "    csv_path = os.path.join(DATABASE_DIR, \"dados_processados.csv\")\n",
        "    \n",
        "    if os.path.exists(csv_path):\n",
        "        print(\"\\nCarregando dados existentes...\")\n",
        "        df = pd.read_csv(csv_path)\n",
        "        dados_processados = []\n",
        "        \n",
        "        for _, row in df.iterrows():\n",
        "            item = {\n",
        "                'id': row.get('ID', ''),\n",
        "                'titulo': row.get('ID', '').split('/')[-1].replace('-', ' ').replace('.html', '').title(),\n",
        "                'texto_bruto': row.get('Texto_Bruto', ''),\n",
        "                'tokens_normalizados': row.get('Tokens_Normalizados', '').split() if row.get('Tokens_Normalizados') else []\n",
        "            }\n",
        "            dados_processados.append(item)\n",
        "        \n",
        "        print(f\"Dados carregados: {len(dados_processados)} posts\")\n",
        "    else:\n",
        "        print(\"\\nExecutando scraping...\")\n",
        "        scraper = AdalbertoScraper()\n",
        "        scraper.processar_lista_posts()\n",
        "        dados_processados = scraper.resultados\n",
        "        scraper.close()\n",
        "        \n",
        "        if not dados_processados:\n",
        "            print(\"Nenhum dado obtido do scraping!\")\n",
        "            return None\n",
        "        \n",
        "        exportar_resultados_csv(dados_processados)\n",
        "    \n",
        "    # FASE 2: Análise básica de modelos\n",
        "    print(\"\\nFASE 2: COMPARAÇÃO BÁSICA DE MODELOS\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    comparador = ComparadorModelos()\n",
        "    resultados_comparacao = comparador.comparar_modelos(dados_processados)\n",
        "    \n",
        "    # FASE 3: Análises avançadas\n",
        "    print(\"\\nFASE 3: ANÁLISES AVANÇADAS\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    analisador = AnalisadorAvancado(comparador)\n",
        "    \n",
        "    # Análise de similaridades com heatmaps\n",
        "    analisador.analisar_similaridades(dados_processados, mostrar_heatmaps=True)\n",
        "    \n",
        "    # Análise de clusterização com scatter plots\n",
        "    df_clusters = analisador.analisar_clusters(dados_processados, n_clusters=3, mostrar_scatter=True)\n",
        "    \n",
        "    # Relatório detalhado de clusters\n",
        "    analisador.gerar_relatorio_clusters(dados_processados, n_clusters=3)\n",
        "    \n",
        "    # FASE 4: Relatórios finais\n",
        "    print(\"\\nFASE 4: RELATÓRIOS FINAIS\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    relatorio = gerar_relatorio_comparativo(resultados_comparacao)\n",
        "    print(relatorio)\n",
        "    \n",
        "    salvar_resultados_comparacao(resultados_comparacao)\n",
        "    plotar_comparacao_modelos(resultados_comparacao)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ANÁLISE COMPLETA CONCLUÍDA!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"Arquivos gerados:\")\n",
        "    print(f\"  • {DATABASE_DIR}/dados_processados.csv\")\n",
        "    print(f\"  • {DATABASE_DIR}/relatorio_comparativo.txt\")\n",
        "    print(f\"  • {DATABASE_DIR}/relatorio_clusters.txt\")\n",
        "    print(f\"  • {DATABASE_DIR}/comparacao_modelos.csv\")\n",
        "    print(f\"  • {DATABASE_DIR}/comparacao_modelos.png\")\n",
        "    \n",
        "    return {\n",
        "        'dados_processados': dados_processados,\n",
        "        'resultados_comparacao': resultados_comparacao,\n",
        "        'analisador_avancado': analisador,\n",
        "        'df_clusters': df_clusters\n",
        "    }\n",
        "\n",
        "print(\"Função de análise completa avançada implementada\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Execução das Análises Avançadas\n",
        "\n",
        "Agora vamos executar as novas funcionalidades de clusterização e similaridade!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute esta célula para realizar todas as análises avançadas\n",
        "resultados_completos = executar_analise_completa_avancada()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exemplos de Uso Individual das Funcionalidades\n",
        "\n",
        "Se quiser usar apenas funcionalidades específicas:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo 1: Apenas heatmaps de similaridade\n",
        "\"\"\"\n",
        "comparador = ComparadorModelos()\n",
        "dados = [...] # seus dados processados\n",
        "analisador = AnalisadorAvancado(comparador)\n",
        "analisador.analisar_similaridades(dados, mostrar_heatmaps=True)\n",
        "\"\"\"\n",
        "\n",
        "# Exemplo 2: Apenas clusterização 2D\n",
        "\"\"\"\n",
        "analisador.analisar_clusters(dados, n_clusters=4, mostrar_scatter=True)\n",
        "\"\"\"\n",
        "\n",
        "# Exemplo 3: Relatório detalhado de clusters\n",
        "\"\"\"\n",
        "analisador.gerar_relatorio_clusters(dados, n_clusters=3)\n",
        "\"\"\"\n",
        "\n",
        "print(\"Exemplos prontos para uso!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Execução Principal\n",
        "\n",
        "Aqui você pode executar todo o pipeline: scraping, processamento PLN e comparação de modelos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def executar_pipeline_completo():\n",
        "    print(\"Iniciando Pipeline Completo\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    print(\"\\nFASE 1: WEB SCRAPING E PROCESSAMENTO PLN\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    scraper = AdalbertoScraper()\n",
        "    \n",
        "    try:\n",
        "        scraper.processar_lista_posts()\n",
        "        \n",
        "        if not scraper.resultados:\n",
        "            print(\"Nenhum resultado obtido do scraping\")\n",
        "            return\n",
        "        \n",
        "        exportar_resultados_csv(scraper.resultados)\n",
        "        \n",
        "        print(f\"\\nDados coletados: {len(scraper.resultados)} posts\")\n",
        "        \n",
        "        print(\"\\nFASE 2: COMPARAÇÃO DE MODELOS\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        comparador = ComparadorModelos()\n",
        "        resultados_comparacao = comparador.comparar_modelos(scraper.resultados)\n",
        "        \n",
        "        print(\"\\nFASE 3: RELATÓRIOS E VISUALIZAÇÕES\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        relatorio = gerar_relatorio_comparativo(resultados_comparacao)\n",
        "        print(\"\\n\" + relatorio)\n",
        "        \n",
        "        salvar_resultados_comparacao(resultados_comparacao)\n",
        "        \n",
        "        plotar_comparacao_modelos(resultados_comparacao)\n",
        "        \n",
        "        print(\"\\nPIPELINE CONCLUÍDO COM SUCESSO!\")\n",
        "        print(f\"Todos os arquivos salvos em: {DATABASE_DIR}/\")\n",
        "        \n",
        "        return scraper.resultados, resultados_comparacao\n",
        "        \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nProcessamento interrompido pelo usuário\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"\\nErro crítico: {e}\")\n",
        "        return None, None\n",
        "    finally:\n",
        "        scraper.close()\n",
        "\n",
        "def executar_apenas_comparacao():\n",
        "    print(\"Executando Apenas Comparação de Modelos\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    csv_path = os.path.join(DATABASE_DIR, \"dados_processados.csv\")\n",
        "    \n",
        "    if not os.path.exists(csv_path):\n",
        "        print(f\"Arquivo não encontrado: {csv_path}\")\n",
        "        print(\"Execute primeiro o pipeline completo ou coloque dados na pasta database/trabalho2/\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"Carregando dados de: {csv_path}\")\n",
        "    df = pd.read_csv(csv_path)\n",
        "    \n",
        "    dados_processados = []\n",
        "    for _, row in df.iterrows():\n",
        "        item = {\n",
        "            'id': row.get('ID', ''),\n",
        "            'texto_bruto': row.get('Texto_Bruto', ''),\n",
        "            'tokens_normalizados': row.get('Tokens_Normalizados', '').split() if row.get('Tokens_Normalizados') else []\n",
        "        }\n",
        "        dados_processados.append(item)\n",
        "    \n",
        "    print(f\"{len(dados_processados)} documentos carregados\")\n",
        "    \n",
        "    comparador = ComparadorModelos()\n",
        "    resultados_comparacao = comparador.comparar_modelos(dados_processados)\n",
        "    \n",
        "    relatorio = gerar_relatorio_comparativo(resultados_comparacao)\n",
        "    print(\"\\n\" + relatorio)\n",
        "    \n",
        "    salvar_resultados_comparacao(resultados_comparacao)\n",
        "    plotar_comparacao_modelos(resultados_comparacao)\n",
        "    \n",
        "    print(\"\\nANÁLISE CONCLUÍDA!\")\n",
        "    return resultados_comparacao\n",
        "\n",
        "print(\"Funções de execução configuradas\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Fase 1: Baixando os posts e executando o scraper**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scraper = AdalbertoScraper()\n",
        "scraper.processar_lista_posts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Fase 2: Realizando comparação dos modelos (TF-IDF, Word2Vec, BERT)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 🎯 Funcionalidades de Classificação Naive Bayes (RECÉM-IMPLEMENTADAS!)\n",
        "\n",
        "### **O que foi adicionado:**\n",
        "- **✅ Classificação por Clusters**: Usa clusters K-Means como labels para treinar classificador\n",
        "- **✅ Classificação Temática**: Categorização automática baseada em palavras-chave:\n",
        "  - **História**: posts sobre eventos históricos, colonização alemã\n",
        "  - **Biografia**: textos sobre Dr. Hermann Blumenau e outras personalidades\n",
        "  - **Cultura**: tradições, festas, costumes alemães\n",
        "  - **Geografia**: locais, regiões, territórios\n",
        "  - **Economia**: empresas, indústria, desenvolvimento\n",
        "- **✅ Múltiplos Algoritmos**: MultinomialNB e GaussianNB para comparação\n",
        "- **✅ Avaliação Robusta**: Accuracy, precision, recall, F1-score e cross-validation\n",
        "- **✅ Visualizações**: Matrizes de confusão interativas e gráficos comparativos\n",
        "- **✅ Relatórios Automáticos**: Análise detalhada salva em arquivo\n",
        "\n",
        "### **Arquivos adicionais gerados:**\n",
        "- `relatorio_classificacao_naive_bayes.txt` - Relatório completo da classificação\n",
        "\n",
        "### **Como usar:**\n",
        "```python\n",
        "# Opção 1: Pipeline completo (recomendado)\n",
        "resultados = executar_pipeline_completo_com_classificacao()\n",
        "\n",
        "# Opção 2: Apenas classificação (se já tem dados processados)\n",
        "classificador = executar_classificacao_naive_bayes(dados, analisador)\n",
        "```\n",
        "\n",
        "### **Benefícios:**\n",
        "1. **Categorização Automática**: Identifica automaticamente temas dos posts\n",
        "2. **Comparação de Métodos**: Testa diferentes embeddings (BERT, Word2Vec, TF-IDF) \n",
        "3. **Performance Transparente**: Métricas detalhadas para avaliar qualidade\n",
        "4. **Escalabilidade**: Pode ser aplicado a novos posts automaticamente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "comparador = ComparadorModelos()\n",
        "resultados = comparador.comparar_modelos(scraper.resultados)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Fase 3: Realizar comparação entre os modelos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotar_comparacao_modelos(resultados)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumo do Projeto (ATUALIZADO) ✅\n",
        "\n",
        "### **Tecnologias Utilizadas**\n",
        "- **Web Scraping**: Selenium WebDriver\n",
        "- **PLN**: NLTK (tokenização, stemming, lemmatização)\n",
        "- **Modelos**: BERT, TF-IDF, Word2Vec\n",
        "- **Análise**: Scikit-learn, Gensim, Transformers\n",
        "- **Visualização**: Matplotlib, Seaborn, **Plotly (NOVO!)**\n",
        "- **Clusterização**: K-Means **✅ implementado**\n",
        "- **Redução de Dimensionalidade**: PCA **✅ implementado**\n",
        "\n",
        "### **Outputs Gerados**\n",
        "1. `dados_processados.csv` - Dados estruturados conforme aula 4\n",
        "2. `relatorio_comparativo.txt` - Análise detalhada dos modelos\n",
        "3. `comparacao_modelos.csv` - Estatísticas em formato tabular\n",
        "4. `comparacao_modelos.png` - Gráficos comparativos\n",
        "5. **`relatorio_clusters.txt` - Relatório detalhado de clusterização ✅ NOVO!**\n",
        "6. Arquivos individuais `.txt` dos posts coletados\n",
        "7. **Heatmaps interativos de similaridade ✅ NOVO!**\n",
        "8. **Scatter plots 2D com clusterização ✅ NOVO!**\n",
        "\n",
        "### **Novas Funcionalidades Implementadas** ✅\n",
        "- **✅ Tabelas de Similaridade**: Heatmaps interativos inspirados no exemplo do professor\n",
        "- **✅ Clusterização K-Means**: Para categorização automática dos posts\n",
        "- **✅ Visualização 2D**: Scatter plots comparativos entre BERT, Word2Vec e TF-IDF\n",
        "- **✅ Relatórios Detalhados**: Análise completa dos clusters encontrados\n",
        "- **✅ Pipeline Integrado**: Tudo funciona junto com o código existente\n",
        "\n",
        "### **Principais Descobertas Esperadas**\n",
        "- **BERT**: Melhor captura semântica, clusters mais coerentes semanticamente\n",
        "- **Word2Vec**: Boa representação semântica, clusters baseados em co-ocorrência\n",
        "- **TF-IDF**: Clusters baseados em frequência de termos, boa separação temática\n",
        "- **Comparação Visual**: Scatter plots mostram diferenças na organização espacial dos documentos\n",
        "\n",
        "### **Como Usar as Novas Funcionalidades**\n",
        "1. **Execute `executar_analise_completa_avancada()`** para análise completa\n",
        "2. **Heatmaps individuais**: Use `AnalisadorAvancado.analisar_similaridades()`\n",
        "3. **Scatter plots**: Use `AnalisadorAvancado.analisar_clusters()`\n",
        "4. **Relatórios**: Use `AnalisadorAvancado.gerar_relatorio_clusters()`\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
